{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ThesisPackage.Environments.collectors.collectors_env_discrete_onehot import Collectors\n",
    "from ThesisPackage.RL.Centralized_PPO.multi_ppo import PPO_Multi_Agent_Centralized\n",
    "from ThesisPackage.RL.Decentralized_PPO.util import flatten_list, reverse_flatten_list_with_agent_list\n",
    "from ThesisPackage.Wrappers.vecWrapper import PettingZooVectorizationParallelWrapper\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(sequence_length=0):\n",
    "    vocab_size = 4\n",
    "    max_episode_steps = 2048\n",
    "    env = Collectors(width=20, height=20, vocab_size=vocab_size, sequence_length=sequence_length, max_timesteps=max_episode_steps, timestep_countdown=15)\n",
    "    # env = ParallelFrameStack(env, 4)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path=\"models/checkpoints\", vocab_size=3):\n",
    "    models = {}\n",
    "    for model in os.listdir(path):\n",
    "        if \"pt\" in model:\n",
    "            sequence_length = model.split(\"_\")[-1]\n",
    "            sequence_length = int(sequence_length.split(\".\")[0])\n",
    "            if sequence_length > 0:\n",
    "                env = make_env(sequence_length=sequence_length)\n",
    "                state_dict = torch.load(os.path.join(path, model))\n",
    "                try:\n",
    "                    agent = PPO_Multi_Agent_Centralized(env, device=\"cpu\")\n",
    "                    agent.agent.load_state_dict(state_dict)\n",
    "                    models[sequence_length] = agent\n",
    "                except:\n",
    "                    continue\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation(inputs, model, vocab_size, sequence_length):\n",
    "    \n",
    "    # Extract environment inputs\n",
    "    environment_inputs = inputs[:, :-1 * vocab_size * sequence_length]\n",
    "\n",
    "    # Extract original logits\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    original_logits = model(inputs)\n",
    "    original_logits = F.softmax(original_logits, dim=1).detach().numpy()\n",
    "    original_logits = F.log_softmax(torch.tensor(original_logits), dim=1).detach()\n",
    "\n",
    "    perturbation_logits = []\n",
    "    for token in range(vocab_size):\n",
    "        # One-hot encoded sequence of tokens\n",
    "        utterances = np.array([token for _ in range(sequence_length)])\n",
    "        utterances = np.eye(vocab_size)[utterances].flatten()\n",
    "        utterances = np.expand_dims(utterances, axis=0)\n",
    "        utterances = np.repeat(utterances, inputs.shape[0], axis=0)\n",
    "\n",
    "        # Concatenate environment inputs with utterances\n",
    "        perturbation_inputs = np.concatenate((environment_inputs, utterances), axis=1)\n",
    "        perturbation_inputs = torch.tensor(perturbation_inputs, dtype=torch.float32)\n",
    "\n",
    "        # Get logits for perturbed inputs\n",
    "        current_logits = model(perturbation_inputs).detach().numpy()\n",
    "        current_logits = F.softmax(torch.tensor(current_logits), dim=1).detach().numpy()\n",
    "\n",
    "        perturbation_logits.append(current_logits)\n",
    "\n",
    "    divergences = []\n",
    "    for input_array in perturbation_logits:\n",
    "        kl_divergences = []\n",
    "        for i in range(len(input_array)):\n",
    "            q = F.softmax(torch.tensor(input_array[i]), dim=0)\n",
    "            kl_div = F.kl_div(original_logits, q, reduction='batchmean').item()\n",
    "            kl_divergences.append(kl_div)\n",
    "\n",
    "        divergences.append(kl_divergences)\n",
    "    max_divergences = np.max(divergences, axis=0)\n",
    "    return max_divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_perturbation(env, agent, threshold=0.02, number_samples=30000):\n",
    "    language_importances = []\n",
    "    obs, info = env.reset()\n",
    "    state = env.state()\n",
    "    average_length = []\n",
    "    tokens = []\n",
    "    data = {\"player_1\": [], \"player_2\": [], \"player_1_obs\": [], \"player_2_obs\":[], \"player_1_direction\": [], \"player_2_direction\": [], \"target_1\": [], \"target_2\": [], \"target_3\":[]}\n",
    "\n",
    "    with tqdm(total=number_samples) as pbar:\n",
    "        timestep = 0\n",
    "        while True:\n",
    "            for cur_agent in env.agents:\n",
    "                data[cur_agent].append(copy.deepcopy(env.players[cur_agent].position))\n",
    "                data[cur_agent + \"_direction\"].append(copy.deepcopy(env.players[cur_agent].direction))\n",
    "                data[cur_agent + \"_obs\"].append(copy.deepcopy(obs[cur_agent]))\n",
    "            for i in range(env.num_targets):\n",
    "                if len(env.targets) > i:\n",
    "                    target = env.targets[i].position\n",
    "                else:\n",
    "                    target = np.array([-1, -1])\n",
    "                data[\"target_\" + str(i+1)].append(copy.deepcopy(target))\n",
    "            obs = [obs]\n",
    "            state = [state]\n",
    "            obs = np.array(flatten_list(obs))\n",
    "            state = np.array(flatten_list(state))\n",
    "            \n",
    "            # integrated_grads = smoothgrad(obs_track, agent.agent.actor, 0, sigma=1.0, steps=30)\n",
    "            language_perturbation = perturbation(obs, agent.agent.actor, env.vocab_size, env.sequence_length)\n",
    "            language_importances.append(language_perturbation)\n",
    "\n",
    "            if np.any(language_perturbation > threshold):\n",
    "                pbar.update(1)\n",
    "                timestep += 1\n",
    "\n",
    "            if timestep > number_samples:\n",
    "                break\n",
    "\n",
    "            obs = torch.tensor(obs, dtype=torch.float32)\n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                actions, _, _, _ = agent.agent.get_action_and_value(obs, state)\n",
    "                actions = reverse_flatten_list_with_agent_list(actions, agent.agents)\n",
    "\n",
    "            actions = actions[0]\n",
    "            actions = {agent: action.cpu().numpy() for agent, action in actions.items()}\n",
    "\n",
    "            obs, _, truncations, terminations, infos = env.step(actions)\n",
    "            state = env.state()\n",
    "\n",
    "            if any([truncations[agent] or terminations[agent] for agent in env.agents]):\n",
    "                average_length.append(env.timestep)\n",
    "                obs, info = env.reset()\n",
    "                state = env.state()\n",
    "    return np.array(language_importances), data, average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def generate_training_data(language_importances_indices, data, sequence_length=1, vocab_size=3, length=20, height=20):\n",
    "    paddle_1_indices = np.where(language_importances_indices[1] == 0)\n",
    "    paddle_1_indices = language_importances_indices[0][paddle_1_indices]\n",
    "    paddle_1_indices = np.array(paddle_1_indices)[3:-3]\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "        \n",
    "    player_1_data = np.array(data[\"player_1\"])[paddle_1_indices]\n",
    "        \n",
    "    for index in paddle_1_indices:\n",
    "        if data[\"player_1\"][index][0] >= length / 2 and data[\"player_1\"][index][1] < height / 2:\n",
    "            labels.append(1)\n",
    "        elif data[\"player_1\"][index][0] < length / 2 and data[\"player_1\"][index][1] >= height / 2:\n",
    "            labels.append(2)\n",
    "        elif data[\"player_1\"][index][0] >= length / 2 and data[\"player_1\"][index][1] >= height / 2:\n",
    "            labels.append(3)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    targets = np.zeros(len(paddle_1_indices))\n",
    "    targets = np.where((player_1_data[:, 0] >= length / 2) & (player_1_data[:, 1] < height / 2), 1, targets)\n",
    "    targets = np.where((player_1_data[:, 0] < length / 2) & (player_1_data[:, 1] >= height / 2), 2, targets)\n",
    "    targets = np.where((player_1_data[:, 0] >= length / 2) & (player_1_data[:, 1] >= height / 2), 3, targets)\n",
    "    \n",
    "    player_1_obs = np.array(data[\"player_1_obs\"])\n",
    "    player_1_obs = np.array([player_1_obs[index - 3:index + 3] for index in paddle_1_indices])\n",
    "    player_1_lang = player_1_obs[:, :, -1 * sequence_length * vocab_size:]\n",
    "    shape = player_1_lang.shape\n",
    "    new_shape = (shape[0], shape[1] * shape[2])\n",
    "    player_1_lang = player_1_lang.reshape(new_shape)\n",
    "\n",
    "    player_2_obs = np.array(data[\"player_2_obs\"])\n",
    "    player_2_obs = np.array([player_2_obs[index - 3:index + 3] for index in paddle_1_indices])\n",
    "    player_2_lang = player_2_obs[:, :, -1 * sequence_length * vocab_size:]\n",
    "    shape = player_2_lang.shape\n",
    "    new_shape = (shape[0], shape[1] * shape[2])\n",
    "    player_2_lang = player_2_lang.reshape(new_shape)\n",
    "\n",
    "    inputs = np.concatenate((player_1_lang, player_2_lang), axis=1)\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "def generate_training_data_obs(language_importances_indices, data, sequence_length=1, vocab_size=3, length=20, height=20, noise=False):\n",
    "    paddle_1_indices = np.where(language_importances_indices[1] == 0)\n",
    "    paddle_1_indices = language_importances_indices[0][paddle_1_indices]\n",
    "    paddle_1_indices = np.array(paddle_1_indices)[3:-3]\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "        \n",
    "    player_1_data = np.array(data[\"player_1\"])[paddle_1_indices]\n",
    "        \n",
    "    for index in paddle_1_indices:\n",
    "        if data[\"player_2\"][index][0] >= length / 2 and data[\"player_2\"][index][1] < height / 2:\n",
    "            labels.append(1)\n",
    "        elif data[\"player_2\"][index][0] < length / 2 and data[\"player_2\"][index][1] >= height / 2:\n",
    "            labels.append(2)\n",
    "        elif data[\"player_2\"][index][0] >= length / 2 and data[\"player_2\"][index][1] >= height / 2:\n",
    "            labels.append(3)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    \n",
    "    player_1_obs = np.array(data[\"player_1_obs\"])\n",
    "    inputs = np.array([player_1_obs[index] for index in paddle_1_indices])\n",
    "\n",
    "    if noise:\n",
    "        random_utterances = np.random.randint(low=0, high=vocab_size, size=(inputs.shape[0], sequence_length))\n",
    "        random_utterances = np.eye(vocab_size)[random_utterances]\n",
    "        random_utterances = random_utterances.reshape((inputs.shape[0], sequence_length * vocab_size))\n",
    "        inputs[:, -1 * sequence_length * vocab_size:] = random_utterances\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load(\"/Users/cowolff/Documents/GitHub/ma.pong_rl/models/checkpoints_collectors_2/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Step 2: Define the dataset and dataloader\n",
    "class PositionDataset(Dataset):\n",
    "    def __init__(self, data, labels, device):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Step 3: Define the model architecture\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, dataloader, input_size, learning_rate, device):\n",
    "    model = SimpleClassifier(input_size).to(device)\n",
    "\n",
    "    # Step 4: Train the model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.5)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = [0, 0, 0]\n",
    "        total_predictions = [0, 0, 0]\n",
    "        \n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for i in range(3):  # Assuming 3 classes\n",
    "                correct_predictions[i] += ((predicted == i) & (targets == i)).sum().item()\n",
    "                total_predictions[i] += (targets == i).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_accuracy = sum(correct_predictions) / sum(total_predictions)\n",
    "        \n",
    "        # Label-specific accuracy\n",
    "        label_accuracies = [correct_predictions[i] / total_predictions[i] if total_predictions[i] > 0 else 0 for i in range(3)]\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Overall Accuracy: {epoch_accuracy:.4f}\")\n",
    "        for i in range(3):\n",
    "            print(f\"Label {i} Accuracy: {label_accuracies[i]:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return epoch_accuracy, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chance_level(labels):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    index = np.argmax(counts)\n",
    "\n",
    "    chance_level = counts[index] / len(labels)\n",
    "    return chance_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 552/500000 [00:04<1:02:09, 133.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m make_env(sequence_length\u001b[38;5;241m=\u001b[39mseq)\n\u001b[1;32m      4\u001b[0m results[seq] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 6\u001b[0m language_importances, data, average_length \u001b[38;5;241m=\u001b[39m \u001b[43mtest_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m language_importances_larger \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(language_importances \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.02\u001b[39m)\n\u001b[1;32m      9\u001b[0m larger_inputs, larger_labels \u001b[38;5;241m=\u001b[39m generate_training_data(language_importances_larger, data, sequence_length\u001b[38;5;241m=\u001b[39mseq, vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[175], line 43\u001b[0m, in \u001b[0;36mtest_perturbation\u001b[0;34m(env, agent, threshold, number_samples)\u001b[0m\n\u001b[1;32m     41\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 43\u001b[0m     actions, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action_and_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     actions \u001b[38;5;241m=\u001b[39m reverse_flatten_list_with_agent_list(actions, agent\u001b[38;5;241m.\u001b[39magents)\n\u001b[1;32m     46\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/ThesisPackage/RL/Centralized_PPO/agent.py:67\u001b[0m, in \u001b[0;36mAgent.get_action_and_value\u001b[0;34m(self, x, state, action)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([categorical\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;28;01mfor\u001b[39;00m categorical \u001b[38;5;129;01min\u001b[39;00m multi_categoricals])\n\u001b[0;32m---> 67\u001b[0m logprob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([categorical\u001b[38;5;241m.\u001b[39mlog_prob(a) \u001b[38;5;28;01mfor\u001b[39;00m a, categorical \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(action, multi_categoricals)])\n\u001b[1;32m     68\u001b[0m entropy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([categorical\u001b[38;5;241m.\u001b[39mentropy() \u001b[38;5;28;01mfor\u001b[39;00m categorical \u001b[38;5;129;01min\u001b[39;00m multi_categoricals])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mT, logprob\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m), entropy\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(state)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/ThesisPackage/RL/Centralized_PPO/agent.py:67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([categorical\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;28;01mfor\u001b[39;00m categorical \u001b[38;5;129;01min\u001b[39;00m multi_categoricals])\n\u001b[0;32m---> 67\u001b[0m logprob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mcategorical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a, categorical \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(action, multi_categoricals)])\n\u001b[1;32m     68\u001b[0m entropy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([categorical\u001b[38;5;241m.\u001b[39mentropy() \u001b[38;5;28;01mfor\u001b[39;00m categorical \u001b[38;5;129;01min\u001b[39;00m multi_categoricals])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mT, logprob\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m), entropy\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(state)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/torch/distributions/categorical.py:137\u001b[0m, in \u001b[0;36mCategorical.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 137\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m     value, log_pmf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/torch/distributions/distribution.py:310\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m support \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43msupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected value argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    318\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for seq, agent in models.items():\n",
    "    env = make_env(sequence_length=seq)\n",
    "    results[seq] = {}\n",
    "\n",
    "    language_importances, data, average_length = test_perturbation(env, agent, number_samples=500000)\n",
    "\n",
    "    language_importances_larger = np.where(language_importances > 0.02)\n",
    "    larger_inputs, larger_labels = generate_training_data(language_importances_larger, data, sequence_length=seq, vocab_size=4)\n",
    "    dataset = PositionDataset(larger_inputs, larger_labels, \"cpu\")\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    input_size = larger_inputs.shape[1]\n",
    "    accuracy = train(120, dataloader, input_size, 0.001, \"cpu\")\n",
    "    results[seq][\"above threshold\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300001it [35:52, 139.40it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Loss: 1.1294, Overall Accuracy: 0.4921\n",
      "Label 0 Accuracy: 0.5717\n",
      "Label 1 Accuracy: 0.4653\n",
      "Label 2 Accuracy: 0.4251\n",
      "Epoch 2/120, Loss: 1.0970, Overall Accuracy: 0.5116\n",
      "Label 0 Accuracy: 0.5946\n",
      "Label 1 Accuracy: 0.4854\n",
      "Label 2 Accuracy: 0.4399\n",
      "Epoch 3/120, Loss: 1.0849, Overall Accuracy: 0.5174\n",
      "Label 0 Accuracy: 0.5990\n",
      "Label 1 Accuracy: 0.4916\n",
      "Label 2 Accuracy: 0.4469\n",
      "Epoch 4/120, Loss: 1.0766, Overall Accuracy: 0.5229\n",
      "Label 0 Accuracy: 0.6037\n",
      "Label 1 Accuracy: 0.4977\n",
      "Label 2 Accuracy: 0.4529\n",
      "Epoch 5/120, Loss: 1.0709, Overall Accuracy: 0.5250\n",
      "Label 0 Accuracy: 0.6047\n",
      "Label 1 Accuracy: 0.5009\n",
      "Label 2 Accuracy: 0.4551\n",
      "Epoch 6/120, Loss: 1.0675, Overall Accuracy: 0.5272\n",
      "Label 0 Accuracy: 0.6018\n",
      "Label 1 Accuracy: 0.5065\n",
      "Label 2 Accuracy: 0.4596\n",
      "Epoch 7/120, Loss: 1.0641, Overall Accuracy: 0.5277\n",
      "Label 0 Accuracy: 0.6025\n",
      "Label 1 Accuracy: 0.5086\n",
      "Label 2 Accuracy: 0.4580\n",
      "Epoch 8/120, Loss: 1.0615, Overall Accuracy: 0.5295\n",
      "Label 0 Accuracy: 0.6054\n",
      "Label 1 Accuracy: 0.5086\n",
      "Label 2 Accuracy: 0.4606\n",
      "Epoch 9/120, Loss: 1.0588, Overall Accuracy: 0.5315\n",
      "Label 0 Accuracy: 0.6066\n",
      "Label 1 Accuracy: 0.5116\n",
      "Label 2 Accuracy: 0.4625\n",
      "Epoch 10/120, Loss: 1.0577, Overall Accuracy: 0.5338\n",
      "Label 0 Accuracy: 0.6065\n",
      "Label 1 Accuracy: 0.5153\n",
      "Label 2 Accuracy: 0.4661\n",
      "Epoch 11/120, Loss: 1.0563, Overall Accuracy: 0.5318\n",
      "Label 0 Accuracy: 0.6048\n",
      "Label 1 Accuracy: 0.5141\n",
      "Label 2 Accuracy: 0.4627\n",
      "Epoch 12/120, Loss: 1.0545, Overall Accuracy: 0.5336\n",
      "Label 0 Accuracy: 0.6077\n",
      "Label 1 Accuracy: 0.5137\n",
      "Label 2 Accuracy: 0.4658\n",
      "Epoch 13/120, Loss: 1.0532, Overall Accuracy: 0.5338\n",
      "Label 0 Accuracy: 0.6064\n",
      "Label 1 Accuracy: 0.5160\n",
      "Label 2 Accuracy: 0.4653\n",
      "Epoch 14/120, Loss: 1.0519, Overall Accuracy: 0.5359\n",
      "Label 0 Accuracy: 0.6069\n",
      "Label 1 Accuracy: 0.5205\n",
      "Label 2 Accuracy: 0.4666\n",
      "Epoch 15/120, Loss: 1.0512, Overall Accuracy: 0.5349\n",
      "Label 0 Accuracy: 0.6076\n",
      "Label 1 Accuracy: 0.5157\n",
      "Label 2 Accuracy: 0.4680\n",
      "Epoch 16/120, Loss: 1.0505, Overall Accuracy: 0.5356\n",
      "Label 0 Accuracy: 0.6070\n",
      "Label 1 Accuracy: 0.5160\n",
      "Label 2 Accuracy: 0.4706\n",
      "Epoch 17/120, Loss: 1.0492, Overall Accuracy: 0.5355\n",
      "Label 0 Accuracy: 0.6047\n",
      "Label 1 Accuracy: 0.5180\n",
      "Label 2 Accuracy: 0.4706\n",
      "Epoch 18/120, Loss: 1.0486, Overall Accuracy: 0.5362\n",
      "Label 0 Accuracy: 0.6064\n",
      "Label 1 Accuracy: 0.5186\n",
      "Label 2 Accuracy: 0.4706\n",
      "Epoch 19/120, Loss: 1.0475, Overall Accuracy: 0.5347\n",
      "Label 0 Accuracy: 0.6049\n",
      "Label 1 Accuracy: 0.5151\n",
      "Label 2 Accuracy: 0.4711\n",
      "Epoch 20/120, Loss: 1.0467, Overall Accuracy: 0.5360\n",
      "Label 0 Accuracy: 0.6043\n",
      "Label 1 Accuracy: 0.5182\n",
      "Label 2 Accuracy: 0.4728\n",
      "Epoch 21/120, Loss: 1.0457, Overall Accuracy: 0.5359\n",
      "Label 0 Accuracy: 0.6056\n",
      "Label 1 Accuracy: 0.5183\n",
      "Label 2 Accuracy: 0.4706\n",
      "Epoch 22/120, Loss: 1.0456, Overall Accuracy: 0.5375\n",
      "Label 0 Accuracy: 0.6071\n",
      "Label 1 Accuracy: 0.5189\n",
      "Label 2 Accuracy: 0.4738\n",
      "Epoch 23/120, Loss: 1.0450, Overall Accuracy: 0.5351\n",
      "Label 0 Accuracy: 0.6049\n",
      "Label 1 Accuracy: 0.5182\n",
      "Label 2 Accuracy: 0.4691\n",
      "Epoch 24/120, Loss: 1.0448, Overall Accuracy: 0.5373\n",
      "Label 0 Accuracy: 0.6091\n",
      "Label 1 Accuracy: 0.5180\n",
      "Label 2 Accuracy: 0.4714\n",
      "Epoch 25/120, Loss: 1.0435, Overall Accuracy: 0.5376\n",
      "Label 0 Accuracy: 0.6074\n",
      "Label 1 Accuracy: 0.5194\n",
      "Label 2 Accuracy: 0.4728\n",
      "Epoch 26/120, Loss: 1.0432, Overall Accuracy: 0.5370\n",
      "Label 0 Accuracy: 0.6052\n",
      "Label 1 Accuracy: 0.5198\n",
      "Label 2 Accuracy: 0.4732\n",
      "Epoch 27/120, Loss: 1.0432, Overall Accuracy: 0.5376\n",
      "Label 0 Accuracy: 0.6067\n",
      "Label 1 Accuracy: 0.5205\n",
      "Label 2 Accuracy: 0.4726\n",
      "Epoch 28/120, Loss: 1.0424, Overall Accuracy: 0.5383\n",
      "Label 0 Accuracy: 0.6063\n",
      "Label 1 Accuracy: 0.5230\n",
      "Label 2 Accuracy: 0.4725\n",
      "Epoch 29/120, Loss: 1.0420, Overall Accuracy: 0.5380\n",
      "Label 0 Accuracy: 0.6064\n",
      "Label 1 Accuracy: 0.5193\n",
      "Label 2 Accuracy: 0.4757\n",
      "Epoch 30/120, Loss: 1.0415, Overall Accuracy: 0.5385\n",
      "Label 0 Accuracy: 0.6068\n",
      "Label 1 Accuracy: 0.5198\n",
      "Label 2 Accuracy: 0.4761\n",
      "Epoch 31/120, Loss: 1.0408, Overall Accuracy: 0.5378\n",
      "Label 0 Accuracy: 0.6055\n",
      "Label 1 Accuracy: 0.5208\n",
      "Label 2 Accuracy: 0.4745\n",
      "Epoch 32/120, Loss: 1.0405, Overall Accuracy: 0.5400\n",
      "Label 0 Accuracy: 0.6083\n",
      "Label 1 Accuracy: 0.5224\n",
      "Label 2 Accuracy: 0.4766\n",
      "Epoch 33/120, Loss: 1.0404, Overall Accuracy: 0.5397\n",
      "Label 0 Accuracy: 0.6098\n",
      "Label 1 Accuracy: 0.5214\n",
      "Label 2 Accuracy: 0.4748\n",
      "Epoch 34/120, Loss: 1.0402, Overall Accuracy: 0.5388\n",
      "Label 0 Accuracy: 0.6078\n",
      "Label 1 Accuracy: 0.5196\n",
      "Label 2 Accuracy: 0.4763\n",
      "Epoch 35/120, Loss: 1.0398, Overall Accuracy: 0.5398\n",
      "Label 0 Accuracy: 0.6084\n",
      "Label 1 Accuracy: 0.5222\n",
      "Label 2 Accuracy: 0.4760\n",
      "Epoch 36/120, Loss: 1.0396, Overall Accuracy: 0.5393\n",
      "Label 0 Accuracy: 0.6077\n",
      "Label 1 Accuracy: 0.5224\n",
      "Label 2 Accuracy: 0.4750\n",
      "Epoch 37/120, Loss: 1.0391, Overall Accuracy: 0.5403\n",
      "Label 0 Accuracy: 0.6109\n",
      "Label 1 Accuracy: 0.5225\n",
      "Label 2 Accuracy: 0.4743\n",
      "Epoch 38/120, Loss: 1.0389, Overall Accuracy: 0.5394\n",
      "Label 0 Accuracy: 0.6096\n",
      "Label 1 Accuracy: 0.5218\n",
      "Label 2 Accuracy: 0.4735\n",
      "Epoch 39/120, Loss: 1.0388, Overall Accuracy: 0.5401\n",
      "Label 0 Accuracy: 0.6097\n",
      "Label 1 Accuracy: 0.5222\n",
      "Label 2 Accuracy: 0.4753\n",
      "Epoch 40/120, Loss: 1.0385, Overall Accuracy: 0.5399\n",
      "Label 0 Accuracy: 0.6094\n",
      "Label 1 Accuracy: 0.5213\n",
      "Label 2 Accuracy: 0.4761\n",
      "Epoch 41/120, Loss: 1.0379, Overall Accuracy: 0.5396\n",
      "Label 0 Accuracy: 0.6083\n",
      "Label 1 Accuracy: 0.5220\n",
      "Label 2 Accuracy: 0.4757\n",
      "Epoch 42/120, Loss: 1.0378, Overall Accuracy: 0.5399\n",
      "Label 0 Accuracy: 0.6085\n",
      "Label 1 Accuracy: 0.5237\n",
      "Label 2 Accuracy: 0.4746\n",
      "Epoch 43/120, Loss: 1.0377, Overall Accuracy: 0.5407\n",
      "Label 0 Accuracy: 0.6092\n",
      "Label 1 Accuracy: 0.5230\n",
      "Label 2 Accuracy: 0.4772\n",
      "Epoch 44/120, Loss: 1.0370, Overall Accuracy: 0.5401\n",
      "Label 0 Accuracy: 0.6095\n",
      "Label 1 Accuracy: 0.5222\n",
      "Label 2 Accuracy: 0.4758\n",
      "Epoch 45/120, Loss: 1.0370, Overall Accuracy: 0.5416\n",
      "Label 0 Accuracy: 0.6105\n",
      "Label 1 Accuracy: 0.5235\n",
      "Label 2 Accuracy: 0.4780\n",
      "Epoch 46/120, Loss: 1.0370, Overall Accuracy: 0.5407\n",
      "Label 0 Accuracy: 0.6096\n",
      "Label 1 Accuracy: 0.5225\n",
      "Label 2 Accuracy: 0.4771\n",
      "Epoch 47/120, Loss: 1.0367, Overall Accuracy: 0.5420\n",
      "Label 0 Accuracy: 0.6118\n",
      "Label 1 Accuracy: 0.5245\n",
      "Label 2 Accuracy: 0.4767\n",
      "Epoch 48/120, Loss: 1.0363, Overall Accuracy: 0.5416\n",
      "Label 0 Accuracy: 0.6097\n",
      "Label 1 Accuracy: 0.5257\n",
      "Label 2 Accuracy: 0.4764\n",
      "Epoch 49/120, Loss: 1.0365, Overall Accuracy: 0.5413\n",
      "Label 0 Accuracy: 0.6118\n",
      "Label 1 Accuracy: 0.5250\n",
      "Label 2 Accuracy: 0.4739\n",
      "Epoch 50/120, Loss: 1.0361, Overall Accuracy: 0.5401\n",
      "Label 0 Accuracy: 0.6090\n",
      "Label 1 Accuracy: 0.5238\n",
      "Label 2 Accuracy: 0.4745\n",
      "Epoch 51/120, Loss: 1.0358, Overall Accuracy: 0.5415\n",
      "Label 0 Accuracy: 0.6108\n",
      "Label 1 Accuracy: 0.5234\n",
      "Label 2 Accuracy: 0.4777\n",
      "Epoch 52/120, Loss: 1.0357, Overall Accuracy: 0.5417\n",
      "Label 0 Accuracy: 0.6110\n",
      "Label 1 Accuracy: 0.5247\n",
      "Label 2 Accuracy: 0.4763\n",
      "Epoch 53/120, Loss: 1.0356, Overall Accuracy: 0.5425\n",
      "Label 0 Accuracy: 0.6111\n",
      "Label 1 Accuracy: 0.5260\n",
      "Label 2 Accuracy: 0.4774\n",
      "Epoch 54/120, Loss: 1.0351, Overall Accuracy: 0.5424\n",
      "Label 0 Accuracy: 0.6119\n",
      "Label 1 Accuracy: 0.5253\n",
      "Label 2 Accuracy: 0.4768\n",
      "Epoch 55/120, Loss: 1.0350, Overall Accuracy: 0.5406\n",
      "Label 0 Accuracy: 0.6098\n",
      "Label 1 Accuracy: 0.5235\n",
      "Label 2 Accuracy: 0.4757\n",
      "Epoch 56/120, Loss: 1.0348, Overall Accuracy: 0.5424\n",
      "Label 0 Accuracy: 0.6113\n",
      "Label 1 Accuracy: 0.5245\n",
      "Label 2 Accuracy: 0.4787\n",
      "Epoch 57/120, Loss: 1.0350, Overall Accuracy: 0.5423\n",
      "Label 0 Accuracy: 0.6120\n",
      "Label 1 Accuracy: 0.5266\n",
      "Label 2 Accuracy: 0.4752\n",
      "Epoch 58/120, Loss: 1.0348, Overall Accuracy: 0.5421\n",
      "Label 0 Accuracy: 0.6092\n",
      "Label 1 Accuracy: 0.5260\n",
      "Label 2 Accuracy: 0.4785\n",
      "Epoch 59/120, Loss: 1.0345, Overall Accuracy: 0.5427\n",
      "Label 0 Accuracy: 0.6135\n",
      "Label 1 Accuracy: 0.5255\n",
      "Label 2 Accuracy: 0.4758\n",
      "Epoch 60/120, Loss: 1.0341, Overall Accuracy: 0.5431\n",
      "Label 0 Accuracy: 0.6116\n",
      "Label 1 Accuracy: 0.5275\n",
      "Label 2 Accuracy: 0.4772\n",
      "Epoch 61/120, Loss: 1.0338, Overall Accuracy: 0.5430\n",
      "Label 0 Accuracy: 0.6117\n",
      "Label 1 Accuracy: 0.5255\n",
      "Label 2 Accuracy: 0.4789\n",
      "Epoch 62/120, Loss: 1.0341, Overall Accuracy: 0.5425\n",
      "Label 0 Accuracy: 0.6123\n",
      "Label 1 Accuracy: 0.5253\n",
      "Label 2 Accuracy: 0.4768\n",
      "Epoch 63/120, Loss: 1.0341, Overall Accuracy: 0.5419\n",
      "Label 0 Accuracy: 0.6106\n",
      "Label 1 Accuracy: 0.5237\n",
      "Label 2 Accuracy: 0.4786\n",
      "Epoch 64/120, Loss: 1.0339, Overall Accuracy: 0.5422\n",
      "Label 0 Accuracy: 0.6115\n",
      "Label 1 Accuracy: 0.5269\n",
      "Label 2 Accuracy: 0.4752\n",
      "Epoch 65/120, Loss: 1.0337, Overall Accuracy: 0.5434\n",
      "Label 0 Accuracy: 0.6113\n",
      "Label 1 Accuracy: 0.5291\n",
      "Label 2 Accuracy: 0.4767\n",
      "Epoch 66/120, Loss: 1.0336, Overall Accuracy: 0.5419\n",
      "Label 0 Accuracy: 0.6100\n",
      "Label 1 Accuracy: 0.5252\n",
      "Label 2 Accuracy: 0.4778\n",
      "Epoch 67/120, Loss: 1.0331, Overall Accuracy: 0.5429\n",
      "Label 0 Accuracy: 0.6114\n",
      "Label 1 Accuracy: 0.5256\n",
      "Label 2 Accuracy: 0.4789\n",
      "Epoch 68/120, Loss: 1.0332, Overall Accuracy: 0.5425\n",
      "Label 0 Accuracy: 0.6118\n",
      "Label 1 Accuracy: 0.5248\n",
      "Label 2 Accuracy: 0.4781\n",
      "Epoch 69/120, Loss: 1.0333, Overall Accuracy: 0.5428\n",
      "Label 0 Accuracy: 0.6118\n",
      "Label 1 Accuracy: 0.5244\n",
      "Label 2 Accuracy: 0.4795\n",
      "Epoch 70/120, Loss: 1.0330, Overall Accuracy: 0.5444\n",
      "Label 0 Accuracy: 0.6120\n",
      "Label 1 Accuracy: 0.5291\n",
      "Label 2 Accuracy: 0.4794\n",
      "Epoch 71/120, Loss: 1.0327, Overall Accuracy: 0.5436\n",
      "Label 0 Accuracy: 0.6131\n",
      "Label 1 Accuracy: 0.5301\n",
      "Label 2 Accuracy: 0.4740\n",
      "Epoch 72/120, Loss: 1.0329, Overall Accuracy: 0.5434\n",
      "Label 0 Accuracy: 0.6124\n",
      "Label 1 Accuracy: 0.5249\n",
      "Label 2 Accuracy: 0.4800\n",
      "Epoch 73/120, Loss: 1.0330, Overall Accuracy: 0.5428\n",
      "Label 0 Accuracy: 0.6107\n",
      "Label 1 Accuracy: 0.5269\n",
      "Label 2 Accuracy: 0.4781\n",
      "Epoch 74/120, Loss: 1.0324, Overall Accuracy: 0.5433\n",
      "Label 0 Accuracy: 0.6121\n",
      "Label 1 Accuracy: 0.5267\n",
      "Label 2 Accuracy: 0.4782\n",
      "Epoch 75/120, Loss: 1.0323, Overall Accuracy: 0.5433\n",
      "Label 0 Accuracy: 0.6144\n",
      "Label 1 Accuracy: 0.5259\n",
      "Label 2 Accuracy: 0.4761\n",
      "Epoch 76/120, Loss: 1.0323, Overall Accuracy: 0.5443\n",
      "Label 0 Accuracy: 0.6127\n",
      "Label 1 Accuracy: 0.5274\n",
      "Label 2 Accuracy: 0.4798\n",
      "Epoch 77/120, Loss: 1.0325, Overall Accuracy: 0.5431\n",
      "Label 0 Accuracy: 0.6137\n",
      "Label 1 Accuracy: 0.5248\n",
      "Label 2 Accuracy: 0.4778\n",
      "Epoch 78/120, Loss: 1.0326, Overall Accuracy: 0.5439\n",
      "Label 0 Accuracy: 0.6151\n",
      "Label 1 Accuracy: 0.5261\n",
      "Label 2 Accuracy: 0.4771\n",
      "Epoch 79/120, Loss: 1.0321, Overall Accuracy: 0.5431\n",
      "Label 0 Accuracy: 0.6113\n",
      "Label 1 Accuracy: 0.5280\n",
      "Label 2 Accuracy: 0.4769\n",
      "Epoch 80/120, Loss: 1.0316, Overall Accuracy: 0.5436\n",
      "Label 0 Accuracy: 0.6136\n",
      "Label 1 Accuracy: 0.5273\n",
      "Label 2 Accuracy: 0.4766\n",
      "Epoch 81/120, Loss: 1.0238, Overall Accuracy: 0.5479\n",
      "Label 0 Accuracy: 0.6160\n",
      "Label 1 Accuracy: 0.5303\n",
      "Label 2 Accuracy: 0.4847\n",
      "Epoch 82/120, Loss: 1.0227, Overall Accuracy: 0.5486\n",
      "Label 0 Accuracy: 0.6167\n",
      "Label 1 Accuracy: 0.5321\n",
      "Label 2 Accuracy: 0.4841\n",
      "Epoch 83/120, Loss: 1.0223, Overall Accuracy: 0.5484\n",
      "Label 0 Accuracy: 0.6164\n",
      "Label 1 Accuracy: 0.5307\n",
      "Label 2 Accuracy: 0.4856\n",
      "Epoch 84/120, Loss: 1.0223, Overall Accuracy: 0.5477\n",
      "Label 0 Accuracy: 0.6160\n",
      "Label 1 Accuracy: 0.5321\n",
      "Label 2 Accuracy: 0.4819\n",
      "Epoch 85/120, Loss: 1.0224, Overall Accuracy: 0.5480\n",
      "Label 0 Accuracy: 0.6160\n",
      "Label 1 Accuracy: 0.5313\n",
      "Label 2 Accuracy: 0.4838\n",
      "Epoch 86/120, Loss: 1.0225, Overall Accuracy: 0.5484\n",
      "Label 0 Accuracy: 0.6154\n",
      "Label 1 Accuracy: 0.5334\n",
      "Label 2 Accuracy: 0.4836\n",
      "Epoch 87/120, Loss: 1.0221, Overall Accuracy: 0.5487\n",
      "Label 0 Accuracy: 0.6158\n",
      "Label 1 Accuracy: 0.5325\n",
      "Label 2 Accuracy: 0.4851\n",
      "Epoch 88/120, Loss: 1.0218, Overall Accuracy: 0.5487\n",
      "Label 0 Accuracy: 0.6149\n",
      "Label 1 Accuracy: 0.5327\n",
      "Label 2 Accuracy: 0.4860\n",
      "Epoch 89/120, Loss: 1.0218, Overall Accuracy: 0.5491\n",
      "Label 0 Accuracy: 0.6169\n",
      "Label 1 Accuracy: 0.5340\n",
      "Label 2 Accuracy: 0.4836\n",
      "Epoch 90/120, Loss: 1.0218, Overall Accuracy: 0.5479\n",
      "Label 0 Accuracy: 0.6146\n",
      "Label 1 Accuracy: 0.5314\n",
      "Label 2 Accuracy: 0.4852\n",
      "Epoch 91/120, Loss: 1.0218, Overall Accuracy: 0.5481\n",
      "Label 0 Accuracy: 0.6163\n",
      "Label 1 Accuracy: 0.5313\n",
      "Label 2 Accuracy: 0.4837\n",
      "Epoch 92/120, Loss: 1.0218, Overall Accuracy: 0.5478\n",
      "Label 0 Accuracy: 0.6158\n",
      "Label 1 Accuracy: 0.5308\n",
      "Label 2 Accuracy: 0.4842\n",
      "Epoch 93/120, Loss: 1.0216, Overall Accuracy: 0.5490\n",
      "Label 0 Accuracy: 0.6165\n",
      "Label 1 Accuracy: 0.5339\n",
      "Label 2 Accuracy: 0.4838\n",
      "Epoch 94/120, Loss: 1.0217, Overall Accuracy: 0.5482\n",
      "Label 0 Accuracy: 0.6160\n",
      "Label 1 Accuracy: 0.5308\n",
      "Label 2 Accuracy: 0.4851\n",
      "Epoch 95/120, Loss: 1.0214, Overall Accuracy: 0.5493\n",
      "Label 0 Accuracy: 0.6176\n",
      "Label 1 Accuracy: 0.5327\n",
      "Label 2 Accuracy: 0.4847\n",
      "Epoch 96/120, Loss: 1.0215, Overall Accuracy: 0.5491\n",
      "Label 0 Accuracy: 0.6165\n",
      "Label 1 Accuracy: 0.5334\n",
      "Label 2 Accuracy: 0.4845\n",
      "Epoch 97/120, Loss: 1.0210, Overall Accuracy: 0.5491\n",
      "Label 0 Accuracy: 0.6164\n",
      "Label 1 Accuracy: 0.5325\n",
      "Label 2 Accuracy: 0.4860\n",
      "Epoch 98/120, Loss: 1.0211, Overall Accuracy: 0.5493\n",
      "Label 0 Accuracy: 0.6168\n",
      "Label 1 Accuracy: 0.5338\n",
      "Label 2 Accuracy: 0.4844\n",
      "Epoch 99/120, Loss: 1.0214, Overall Accuracy: 0.5481\n",
      "Label 0 Accuracy: 0.6160\n",
      "Label 1 Accuracy: 0.5321\n",
      "Label 2 Accuracy: 0.4832\n",
      "Epoch 100/120, Loss: 1.0210, Overall Accuracy: 0.5489\n",
      "Label 0 Accuracy: 0.6163\n",
      "Label 1 Accuracy: 0.5323\n",
      "Label 2 Accuracy: 0.4854\n",
      "Epoch 101/120, Loss: 1.0212, Overall Accuracy: 0.5493\n",
      "Label 0 Accuracy: 0.6170\n",
      "Label 1 Accuracy: 0.5343\n",
      "Label 2 Accuracy: 0.4838\n",
      "Epoch 102/120, Loss: 1.0208, Overall Accuracy: 0.5493\n",
      "Label 0 Accuracy: 0.6173\n",
      "Label 1 Accuracy: 0.5329\n",
      "Label 2 Accuracy: 0.4850\n",
      "Epoch 103/120, Loss: 1.0209, Overall Accuracy: 0.5503\n",
      "Label 0 Accuracy: 0.6167\n",
      "Label 1 Accuracy: 0.5357\n",
      "Label 2 Accuracy: 0.4858\n",
      "Epoch 104/120, Loss: 1.0210, Overall Accuracy: 0.5489\n",
      "Label 0 Accuracy: 0.6159\n",
      "Label 1 Accuracy: 0.5337\n",
      "Label 2 Accuracy: 0.4843\n",
      "Epoch 105/120, Loss: 1.0210, Overall Accuracy: 0.5492\n",
      "Label 0 Accuracy: 0.6178\n",
      "Label 1 Accuracy: 0.5323\n",
      "Label 2 Accuracy: 0.4847\n",
      "Epoch 106/120, Loss: 1.0207, Overall Accuracy: 0.5487\n",
      "Label 0 Accuracy: 0.6161\n",
      "Label 1 Accuracy: 0.5316\n",
      "Label 2 Accuracy: 0.4857\n",
      "Epoch 107/120, Loss: 1.0208, Overall Accuracy: 0.5486\n",
      "Label 0 Accuracy: 0.6161\n",
      "Label 1 Accuracy: 0.5329\n",
      "Label 2 Accuracy: 0.4839\n",
      "Epoch 108/120, Loss: 1.0209, Overall Accuracy: 0.5483\n",
      "Label 0 Accuracy: 0.6157\n",
      "Label 1 Accuracy: 0.5317\n",
      "Label 2 Accuracy: 0.4849\n",
      "Epoch 109/120, Loss: 1.0209, Overall Accuracy: 0.5495\n",
      "Label 0 Accuracy: 0.6171\n",
      "Label 1 Accuracy: 0.5336\n",
      "Label 2 Accuracy: 0.4849\n",
      "Epoch 110/120, Loss: 1.0204, Overall Accuracy: 0.5495\n",
      "Label 0 Accuracy: 0.6151\n",
      "Label 1 Accuracy: 0.5336\n",
      "Label 2 Accuracy: 0.4874\n",
      "Epoch 111/120, Loss: 1.0206, Overall Accuracy: 0.5496\n",
      "Label 0 Accuracy: 0.6168\n",
      "Label 1 Accuracy: 0.5345\n",
      "Label 2 Accuracy: 0.4847\n",
      "Epoch 112/120, Loss: 1.0207, Overall Accuracy: 0.5491\n",
      "Label 0 Accuracy: 0.6161\n",
      "Label 1 Accuracy: 0.5337\n",
      "Label 2 Accuracy: 0.4847\n",
      "Epoch 113/120, Loss: 1.0205, Overall Accuracy: 0.5492\n",
      "Label 0 Accuracy: 0.6150\n",
      "Label 1 Accuracy: 0.5334\n",
      "Label 2 Accuracy: 0.4866\n",
      "Epoch 114/120, Loss: 1.0206, Overall Accuracy: 0.5497\n",
      "Label 0 Accuracy: 0.6179\n",
      "Label 1 Accuracy: 0.5336\n",
      "Label 2 Accuracy: 0.4846\n",
      "Epoch 115/120, Loss: 1.0208, Overall Accuracy: 0.5489\n",
      "Label 0 Accuracy: 0.6175\n",
      "Label 1 Accuracy: 0.5323\n",
      "Label 2 Accuracy: 0.4841\n",
      "Epoch 116/120, Loss: 1.0205, Overall Accuracy: 0.5492\n",
      "Label 0 Accuracy: 0.6170\n",
      "Label 1 Accuracy: 0.5333\n",
      "Label 2 Accuracy: 0.4847\n",
      "Epoch 117/120, Loss: 1.0204, Overall Accuracy: 0.5494\n",
      "Label 0 Accuracy: 0.6178\n",
      "Label 1 Accuracy: 0.5316\n",
      "Label 2 Accuracy: 0.4861\n",
      "Epoch 118/120, Loss: 1.0204, Overall Accuracy: 0.5495\n",
      "Label 0 Accuracy: 0.6182\n",
      "Label 1 Accuracy: 0.5339\n",
      "Label 2 Accuracy: 0.4834\n",
      "Epoch 119/120, Loss: 1.0201, Overall Accuracy: 0.5499\n",
      "Label 0 Accuracy: 0.6170\n",
      "Label 1 Accuracy: 0.5337\n",
      "Label 2 Accuracy: 0.4864\n",
      "Epoch 120/120, Loss: 1.0202, Overall Accuracy: 0.5487\n",
      "Label 0 Accuracy: 0.6161\n",
      "Label 1 Accuracy: 0.5332\n",
      "Label 2 Accuracy: 0.4842\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [03:42, 134.66it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [03:44, 133.52it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300001it [04:51, 1029.19it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Loss: 0.9340, Overall Accuracy: 0.5609\n",
      "Label 0 Accuracy: 0.5125\n",
      "Label 1 Accuracy: 0.6056\n",
      "Label 2 Accuracy: 0.5593\n",
      "Epoch 2/120, Loss: 0.9009, Overall Accuracy: 0.5674\n",
      "Label 0 Accuracy: 0.5392\n",
      "Label 1 Accuracy: 0.6036\n",
      "Label 2 Accuracy: 0.5554\n",
      "Epoch 3/120, Loss: 0.8942, Overall Accuracy: 0.5702\n",
      "Label 0 Accuracy: 0.5469\n",
      "Label 1 Accuracy: 0.6101\n",
      "Label 2 Accuracy: 0.5495\n",
      "Epoch 4/120, Loss: 0.8903, Overall Accuracy: 0.5730\n",
      "Label 0 Accuracy: 0.5523\n",
      "Label 1 Accuracy: 0.6138\n",
      "Label 2 Accuracy: 0.5487\n",
      "Epoch 5/120, Loss: 0.8874, Overall Accuracy: 0.5750\n",
      "Label 0 Accuracy: 0.5543\n",
      "Label 1 Accuracy: 0.6145\n",
      "Label 2 Accuracy: 0.5521\n",
      "Epoch 6/120, Loss: 0.8849, Overall Accuracy: 0.5789\n",
      "Label 0 Accuracy: 0.5538\n",
      "Label 1 Accuracy: 0.6250\n",
      "Label 2 Accuracy: 0.5532\n",
      "Epoch 7/120, Loss: 0.8831, Overall Accuracy: 0.5792\n",
      "Label 0 Accuracy: 0.5525\n",
      "Label 1 Accuracy: 0.6229\n",
      "Label 2 Accuracy: 0.5575\n",
      "Epoch 8/120, Loss: 0.8815, Overall Accuracy: 0.5816\n",
      "Label 0 Accuracy: 0.5499\n",
      "Label 1 Accuracy: 0.6285\n",
      "Label 2 Accuracy: 0.5612\n",
      "Epoch 9/120, Loss: 0.8800, Overall Accuracy: 0.5839\n",
      "Label 0 Accuracy: 0.5546\n",
      "Label 1 Accuracy: 0.6312\n",
      "Label 2 Accuracy: 0.5610\n",
      "Epoch 10/120, Loss: 0.8789, Overall Accuracy: 0.5847\n",
      "Label 0 Accuracy: 0.5536\n",
      "Label 1 Accuracy: 0.6337\n",
      "Label 2 Accuracy: 0.5618\n",
      "Epoch 11/120, Loss: 0.8776, Overall Accuracy: 0.5849\n",
      "Label 0 Accuracy: 0.5509\n",
      "Label 1 Accuracy: 0.6356\n",
      "Label 2 Accuracy: 0.5627\n",
      "Epoch 12/120, Loss: 0.8764, Overall Accuracy: 0.5860\n",
      "Label 0 Accuracy: 0.5540\n",
      "Label 1 Accuracy: 0.6338\n",
      "Label 2 Accuracy: 0.5653\n",
      "Epoch 13/120, Loss: 0.8752, Overall Accuracy: 0.5869\n",
      "Label 0 Accuracy: 0.5498\n",
      "Label 1 Accuracy: 0.6378\n",
      "Label 2 Accuracy: 0.5677\n",
      "Epoch 14/120, Loss: 0.8742, Overall Accuracy: 0.5885\n",
      "Label 0 Accuracy: 0.5575\n",
      "Label 1 Accuracy: 0.6375\n",
      "Label 2 Accuracy: 0.5653\n",
      "Epoch 15/120, Loss: 0.8733, Overall Accuracy: 0.5885\n",
      "Label 0 Accuracy: 0.5511\n",
      "Label 1 Accuracy: 0.6395\n",
      "Label 2 Accuracy: 0.5693\n",
      "Epoch 16/120, Loss: 0.8727, Overall Accuracy: 0.5887\n",
      "Label 0 Accuracy: 0.5519\n",
      "Label 1 Accuracy: 0.6408\n",
      "Label 2 Accuracy: 0.5676\n",
      "Epoch 17/120, Loss: 0.8718, Overall Accuracy: 0.5895\n",
      "Label 0 Accuracy: 0.5562\n",
      "Label 1 Accuracy: 0.6383\n",
      "Label 2 Accuracy: 0.5687\n",
      "Epoch 18/120, Loss: 0.8713, Overall Accuracy: 0.5899\n",
      "Label 0 Accuracy: 0.5538\n",
      "Label 1 Accuracy: 0.6424\n",
      "Label 2 Accuracy: 0.5678\n",
      "Epoch 19/120, Loss: 0.8707, Overall Accuracy: 0.5910\n",
      "Label 0 Accuracy: 0.5508\n",
      "Label 1 Accuracy: 0.6435\n",
      "Label 2 Accuracy: 0.5728\n",
      "Epoch 20/120, Loss: 0.8700, Overall Accuracy: 0.5895\n",
      "Label 0 Accuracy: 0.5507\n",
      "Label 1 Accuracy: 0.6426\n",
      "Label 2 Accuracy: 0.5693\n",
      "Epoch 21/120, Loss: 0.8696, Overall Accuracy: 0.5894\n",
      "Label 0 Accuracy: 0.5517\n",
      "Label 1 Accuracy: 0.6393\n",
      "Label 2 Accuracy: 0.5717\n",
      "Epoch 22/120, Loss: 0.8691, Overall Accuracy: 0.5925\n",
      "Label 0 Accuracy: 0.5547\n",
      "Label 1 Accuracy: 0.6462\n",
      "Label 2 Accuracy: 0.5708\n",
      "Epoch 23/120, Loss: 0.8687, Overall Accuracy: 0.5915\n",
      "Label 0 Accuracy: 0.5524\n",
      "Label 1 Accuracy: 0.6459\n",
      "Label 2 Accuracy: 0.5703\n",
      "Epoch 24/120, Loss: 0.8682, Overall Accuracy: 0.5911\n",
      "Label 0 Accuracy: 0.5563\n",
      "Label 1 Accuracy: 0.6425\n",
      "Label 2 Accuracy: 0.5691\n",
      "Epoch 25/120, Loss: 0.8681, Overall Accuracy: 0.5916\n",
      "Label 0 Accuracy: 0.5554\n",
      "Label 1 Accuracy: 0.6410\n",
      "Label 2 Accuracy: 0.5730\n",
      "Epoch 26/120, Loss: 0.8675, Overall Accuracy: 0.5914\n",
      "Label 0 Accuracy: 0.5549\n",
      "Label 1 Accuracy: 0.6426\n",
      "Label 2 Accuracy: 0.5712\n",
      "Epoch 27/120, Loss: 0.8676, Overall Accuracy: 0.5920\n",
      "Label 0 Accuracy: 0.5562\n",
      "Label 1 Accuracy: 0.6429\n",
      "Label 2 Accuracy: 0.5713\n",
      "Epoch 28/120, Loss: 0.8675, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5580\n",
      "Label 1 Accuracy: 0.6482\n",
      "Label 2 Accuracy: 0.5672\n",
      "Epoch 29/120, Loss: 0.8669, Overall Accuracy: 0.5915\n",
      "Label 0 Accuracy: 0.5535\n",
      "Label 1 Accuracy: 0.6417\n",
      "Label 2 Accuracy: 0.5740\n",
      "Epoch 30/120, Loss: 0.8668, Overall Accuracy: 0.5920\n",
      "Label 0 Accuracy: 0.5549\n",
      "Label 1 Accuracy: 0.6442\n",
      "Label 2 Accuracy: 0.5713\n",
      "Epoch 31/120, Loss: 0.8667, Overall Accuracy: 0.5924\n",
      "Label 0 Accuracy: 0.5577\n",
      "Label 1 Accuracy: 0.6433\n",
      "Label 2 Accuracy: 0.5706\n",
      "Epoch 32/120, Loss: 0.8662, Overall Accuracy: 0.5920\n",
      "Label 0 Accuracy: 0.5555\n",
      "Label 1 Accuracy: 0.6434\n",
      "Label 2 Accuracy: 0.5717\n",
      "Epoch 33/120, Loss: 0.8662, Overall Accuracy: 0.5918\n",
      "Label 0 Accuracy: 0.5563\n",
      "Label 1 Accuracy: 0.6417\n",
      "Label 2 Accuracy: 0.5720\n",
      "Epoch 34/120, Loss: 0.8662, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5599\n",
      "Label 1 Accuracy: 0.6436\n",
      "Label 2 Accuracy: 0.5693\n",
      "Epoch 35/120, Loss: 0.8653, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5560\n",
      "Label 1 Accuracy: 0.6446\n",
      "Label 2 Accuracy: 0.5719\n",
      "Epoch 36/120, Loss: 0.8658, Overall Accuracy: 0.5921\n",
      "Label 0 Accuracy: 0.5546\n",
      "Label 1 Accuracy: 0.6437\n",
      "Label 2 Accuracy: 0.5726\n",
      "Epoch 37/120, Loss: 0.8653, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5576\n",
      "Label 1 Accuracy: 0.6428\n",
      "Label 2 Accuracy: 0.5734\n",
      "Epoch 38/120, Loss: 0.8651, Overall Accuracy: 0.5915\n",
      "Label 0 Accuracy: 0.5581\n",
      "Label 1 Accuracy: 0.6420\n",
      "Label 2 Accuracy: 0.5689\n",
      "Epoch 39/120, Loss: 0.8651, Overall Accuracy: 0.5924\n",
      "Label 0 Accuracy: 0.5580\n",
      "Label 1 Accuracy: 0.6439\n",
      "Label 2 Accuracy: 0.5699\n",
      "Epoch 40/120, Loss: 0.8647, Overall Accuracy: 0.5929\n",
      "Label 0 Accuracy: 0.5607\n",
      "Label 1 Accuracy: 0.6421\n",
      "Label 2 Accuracy: 0.5705\n",
      "Epoch 41/120, Loss: 0.8649, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5551\n",
      "Label 1 Accuracy: 0.6453\n",
      "Label 2 Accuracy: 0.5719\n",
      "Epoch 42/120, Loss: 0.8647, Overall Accuracy: 0.5926\n",
      "Label 0 Accuracy: 0.5597\n",
      "Label 1 Accuracy: 0.6408\n",
      "Label 2 Accuracy: 0.5721\n",
      "Epoch 43/120, Loss: 0.8649, Overall Accuracy: 0.5923\n",
      "Label 0 Accuracy: 0.5582\n",
      "Label 1 Accuracy: 0.6440\n",
      "Label 2 Accuracy: 0.5693\n",
      "Epoch 44/120, Loss: 0.8644, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5592\n",
      "Label 1 Accuracy: 0.6439\n",
      "Label 2 Accuracy: 0.5695\n",
      "Epoch 45/120, Loss: 0.8643, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5593\n",
      "Label 1 Accuracy: 0.6430\n",
      "Label 2 Accuracy: 0.5704\n",
      "Epoch 46/120, Loss: 0.8640, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5582\n",
      "Label 1 Accuracy: 0.6424\n",
      "Label 2 Accuracy: 0.5734\n",
      "Epoch 47/120, Loss: 0.8640, Overall Accuracy: 0.5939\n",
      "Label 0 Accuracy: 0.5567\n",
      "Label 1 Accuracy: 0.6466\n",
      "Label 2 Accuracy: 0.5726\n",
      "Epoch 48/120, Loss: 0.8639, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5580\n",
      "Label 1 Accuracy: 0.6448\n",
      "Label 2 Accuracy: 0.5711\n",
      "Epoch 49/120, Loss: 0.8638, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5574\n",
      "Label 1 Accuracy: 0.6435\n",
      "Label 2 Accuracy: 0.5716\n",
      "Epoch 50/120, Loss: 0.8635, Overall Accuracy: 0.5936\n",
      "Label 0 Accuracy: 0.5578\n",
      "Label 1 Accuracy: 0.6425\n",
      "Label 2 Accuracy: 0.5751\n",
      "Epoch 51/120, Loss: 0.8638, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5609\n",
      "Label 1 Accuracy: 0.6433\n",
      "Label 2 Accuracy: 0.5696\n",
      "Epoch 52/120, Loss: 0.8632, Overall Accuracy: 0.5928\n",
      "Label 0 Accuracy: 0.5593\n",
      "Label 1 Accuracy: 0.6433\n",
      "Label 2 Accuracy: 0.5703\n",
      "Epoch 53/120, Loss: 0.8634, Overall Accuracy: 0.5917\n",
      "Label 0 Accuracy: 0.5572\n",
      "Label 1 Accuracy: 0.6408\n",
      "Label 2 Accuracy: 0.5716\n",
      "Epoch 54/120, Loss: 0.8633, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5575\n",
      "Label 1 Accuracy: 0.6425\n",
      "Label 2 Accuracy: 0.5739\n",
      "Epoch 55/120, Loss: 0.8634, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5526\n",
      "Label 1 Accuracy: 0.6428\n",
      "Label 2 Accuracy: 0.5771\n",
      "Epoch 56/120, Loss: 0.8633, Overall Accuracy: 0.5952\n",
      "Label 0 Accuracy: 0.5616\n",
      "Label 1 Accuracy: 0.6447\n",
      "Label 2 Accuracy: 0.5739\n",
      "Epoch 57/120, Loss: 0.8632, Overall Accuracy: 0.5940\n",
      "Label 0 Accuracy: 0.5598\n",
      "Label 1 Accuracy: 0.6458\n",
      "Label 2 Accuracy: 0.5708\n",
      "Epoch 58/120, Loss: 0.8629, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5574\n",
      "Label 1 Accuracy: 0.6439\n",
      "Label 2 Accuracy: 0.5726\n",
      "Epoch 59/120, Loss: 0.8629, Overall Accuracy: 0.5921\n",
      "Label 0 Accuracy: 0.5571\n",
      "Label 1 Accuracy: 0.6397\n",
      "Label 2 Accuracy: 0.5743\n",
      "Epoch 60/120, Loss: 0.8631, Overall Accuracy: 0.5925\n",
      "Label 0 Accuracy: 0.5591\n",
      "Label 1 Accuracy: 0.6435\n",
      "Label 2 Accuracy: 0.5694\n",
      "Epoch 61/120, Loss: 0.8628, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5604\n",
      "Label 1 Accuracy: 0.6413\n",
      "Label 2 Accuracy: 0.5725\n",
      "Epoch 62/120, Loss: 0.8626, Overall Accuracy: 0.5910\n",
      "Label 0 Accuracy: 0.5539\n",
      "Label 1 Accuracy: 0.6405\n",
      "Label 2 Accuracy: 0.5730\n",
      "Epoch 63/120, Loss: 0.8626, Overall Accuracy: 0.5930\n",
      "Label 0 Accuracy: 0.5591\n",
      "Label 1 Accuracy: 0.6403\n",
      "Label 2 Accuracy: 0.5744\n",
      "Epoch 64/120, Loss: 0.8627, Overall Accuracy: 0.5936\n",
      "Label 0 Accuracy: 0.5622\n",
      "Label 1 Accuracy: 0.6399\n",
      "Label 2 Accuracy: 0.5736\n",
      "Epoch 65/120, Loss: 0.8625, Overall Accuracy: 0.5930\n",
      "Label 0 Accuracy: 0.5569\n",
      "Label 1 Accuracy: 0.6409\n",
      "Label 2 Accuracy: 0.5759\n",
      "Epoch 66/120, Loss: 0.8625, Overall Accuracy: 0.5923\n",
      "Label 0 Accuracy: 0.5570\n",
      "Label 1 Accuracy: 0.6419\n",
      "Label 2 Accuracy: 0.5725\n",
      "Epoch 67/120, Loss: 0.8625, Overall Accuracy: 0.5919\n",
      "Label 0 Accuracy: 0.5577\n",
      "Label 1 Accuracy: 0.6407\n",
      "Label 2 Accuracy: 0.5720\n",
      "Epoch 68/120, Loss: 0.8623, Overall Accuracy: 0.5921\n",
      "Label 0 Accuracy: 0.5586\n",
      "Label 1 Accuracy: 0.6393\n",
      "Label 2 Accuracy: 0.5734\n",
      "Epoch 69/120, Loss: 0.8623, Overall Accuracy: 0.5941\n",
      "Label 0 Accuracy: 0.5571\n",
      "Label 1 Accuracy: 0.6428\n",
      "Label 2 Accuracy: 0.5770\n",
      "Epoch 70/120, Loss: 0.8622, Overall Accuracy: 0.5926\n",
      "Label 0 Accuracy: 0.5607\n",
      "Label 1 Accuracy: 0.6401\n",
      "Label 2 Accuracy: 0.5720\n",
      "Epoch 71/120, Loss: 0.8622, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5594\n",
      "Label 1 Accuracy: 0.6417\n",
      "Label 2 Accuracy: 0.5729\n",
      "Epoch 72/120, Loss: 0.8619, Overall Accuracy: 0.5926\n",
      "Label 0 Accuracy: 0.5581\n",
      "Label 1 Accuracy: 0.6417\n",
      "Label 2 Accuracy: 0.5728\n",
      "Epoch 73/120, Loss: 0.8621, Overall Accuracy: 0.5927\n",
      "Label 0 Accuracy: 0.5601\n",
      "Label 1 Accuracy: 0.6394\n",
      "Label 2 Accuracy: 0.5734\n",
      "Epoch 74/120, Loss: 0.8620, Overall Accuracy: 0.5943\n",
      "Label 0 Accuracy: 0.5590\n",
      "Label 1 Accuracy: 0.6447\n",
      "Label 2 Accuracy: 0.5737\n",
      "Epoch 75/120, Loss: 0.8619, Overall Accuracy: 0.5931\n",
      "Label 0 Accuracy: 0.5588\n",
      "Label 1 Accuracy: 0.6411\n",
      "Label 2 Accuracy: 0.5741\n",
      "Epoch 76/120, Loss: 0.8621, Overall Accuracy: 0.5914\n",
      "Label 0 Accuracy: 0.5587\n",
      "Label 1 Accuracy: 0.6385\n",
      "Label 2 Accuracy: 0.5720\n",
      "Epoch 77/120, Loss: 0.8621, Overall Accuracy: 0.5922\n",
      "Label 0 Accuracy: 0.5615\n",
      "Label 1 Accuracy: 0.6412\n",
      "Label 2 Accuracy: 0.5686\n",
      "Epoch 78/120, Loss: 0.8618, Overall Accuracy: 0.5916\n",
      "Label 0 Accuracy: 0.5601\n",
      "Label 1 Accuracy: 0.6384\n",
      "Label 2 Accuracy: 0.5714\n",
      "Epoch 79/120, Loss: 0.8617, Overall Accuracy: 0.5932\n",
      "Label 0 Accuracy: 0.5595\n",
      "Label 1 Accuracy: 0.6413\n",
      "Label 2 Accuracy: 0.5734\n",
      "Epoch 80/120, Loss: 0.8623, Overall Accuracy: 0.5920\n",
      "Label 0 Accuracy: 0.5579\n",
      "Label 1 Accuracy: 0.6406\n",
      "Label 2 Accuracy: 0.5722\n",
      "Epoch 81/120, Loss: 0.8557, Overall Accuracy: 0.5958\n",
      "Label 0 Accuracy: 0.5635\n",
      "Label 1 Accuracy: 0.6441\n",
      "Label 2 Accuracy: 0.5747\n",
      "Epoch 82/120, Loss: 0.8551, Overall Accuracy: 0.5995\n",
      "Label 0 Accuracy: 0.5679\n",
      "Label 1 Accuracy: 0.6501\n",
      "Label 2 Accuracy: 0.5750\n",
      "Epoch 83/120, Loss: 0.8548, Overall Accuracy: 0.5978\n",
      "Label 0 Accuracy: 0.5658\n",
      "Label 1 Accuracy: 0.6454\n",
      "Label 2 Accuracy: 0.5772\n",
      "Epoch 84/120, Loss: 0.8547, Overall Accuracy: 0.5971\n",
      "Label 0 Accuracy: 0.5664\n",
      "Label 1 Accuracy: 0.6476\n",
      "Label 2 Accuracy: 0.5720\n",
      "Epoch 85/120, Loss: 0.8547, Overall Accuracy: 0.5987\n",
      "Label 0 Accuracy: 0.5667\n",
      "Label 1 Accuracy: 0.6499\n",
      "Label 2 Accuracy: 0.5740\n",
      "Epoch 86/120, Loss: 0.8544, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5671\n",
      "Label 1 Accuracy: 0.6500\n",
      "Label 2 Accuracy: 0.5729\n",
      "Epoch 87/120, Loss: 0.8546, Overall Accuracy: 0.5986\n",
      "Label 0 Accuracy: 0.5688\n",
      "Label 1 Accuracy: 0.6498\n",
      "Label 2 Accuracy: 0.5719\n",
      "Epoch 88/120, Loss: 0.8546, Overall Accuracy: 0.5974\n",
      "Label 0 Accuracy: 0.5659\n",
      "Label 1 Accuracy: 0.6475\n",
      "Label 2 Accuracy: 0.5734\n",
      "Epoch 89/120, Loss: 0.8545, Overall Accuracy: 0.5981\n",
      "Label 0 Accuracy: 0.5651\n",
      "Label 1 Accuracy: 0.6479\n",
      "Label 2 Accuracy: 0.5759\n",
      "Epoch 90/120, Loss: 0.8543, Overall Accuracy: 0.5973\n",
      "Label 0 Accuracy: 0.5668\n",
      "Label 1 Accuracy: 0.6471\n",
      "Label 2 Accuracy: 0.5729\n",
      "Epoch 91/120, Loss: 0.8543, Overall Accuracy: 0.5990\n",
      "Label 0 Accuracy: 0.5700\n",
      "Label 1 Accuracy: 0.6479\n",
      "Label 2 Accuracy: 0.5741\n",
      "Epoch 92/120, Loss: 0.8545, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5656\n",
      "Label 1 Accuracy: 0.6482\n",
      "Label 2 Accuracy: 0.5765\n",
      "Epoch 93/120, Loss: 0.8543, Overall Accuracy: 0.5979\n",
      "Label 0 Accuracy: 0.5705\n",
      "Label 1 Accuracy: 0.6470\n",
      "Label 2 Accuracy: 0.5710\n",
      "Epoch 94/120, Loss: 0.8545, Overall Accuracy: 0.5984\n",
      "Label 0 Accuracy: 0.5639\n",
      "Label 1 Accuracy: 0.6476\n",
      "Label 2 Accuracy: 0.5786\n",
      "Epoch 95/120, Loss: 0.8542, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5679\n",
      "Label 1 Accuracy: 0.6483\n",
      "Label 2 Accuracy: 0.5741\n",
      "Epoch 96/120, Loss: 0.8543, Overall Accuracy: 0.5979\n",
      "Label 0 Accuracy: 0.5665\n",
      "Label 1 Accuracy: 0.6469\n",
      "Label 2 Accuracy: 0.5752\n",
      "Epoch 97/120, Loss: 0.8542, Overall Accuracy: 0.5997\n",
      "Label 0 Accuracy: 0.5693\n",
      "Label 1 Accuracy: 0.6510\n",
      "Label 2 Accuracy: 0.5733\n",
      "Epoch 98/120, Loss: 0.8542, Overall Accuracy: 0.5990\n",
      "Label 0 Accuracy: 0.5650\n",
      "Label 1 Accuracy: 0.6498\n",
      "Label 2 Accuracy: 0.5769\n",
      "Epoch 99/120, Loss: 0.8540, Overall Accuracy: 0.5980\n",
      "Label 0 Accuracy: 0.5648\n",
      "Label 1 Accuracy: 0.6497\n",
      "Label 2 Accuracy: 0.5740\n",
      "Epoch 100/120, Loss: 0.8540, Overall Accuracy: 0.5984\n",
      "Label 0 Accuracy: 0.5669\n",
      "Label 1 Accuracy: 0.6487\n",
      "Label 2 Accuracy: 0.5744\n",
      "Epoch 101/120, Loss: 0.8541, Overall Accuracy: 0.5980\n",
      "Label 0 Accuracy: 0.5646\n",
      "Label 1 Accuracy: 0.6482\n",
      "Label 2 Accuracy: 0.5758\n",
      "Epoch 102/120, Loss: 0.8540, Overall Accuracy: 0.5983\n",
      "Label 0 Accuracy: 0.5672\n",
      "Label 1 Accuracy: 0.6501\n",
      "Label 2 Accuracy: 0.5723\n",
      "Epoch 103/120, Loss: 0.8540, Overall Accuracy: 0.5973\n",
      "Label 0 Accuracy: 0.5652\n",
      "Label 1 Accuracy: 0.6464\n",
      "Label 2 Accuracy: 0.5749\n",
      "Epoch 104/120, Loss: 0.8538, Overall Accuracy: 0.5973\n",
      "Label 0 Accuracy: 0.5680\n",
      "Label 1 Accuracy: 0.6462\n",
      "Label 2 Accuracy: 0.5724\n",
      "Epoch 105/120, Loss: 0.8540, Overall Accuracy: 0.5984\n",
      "Label 0 Accuracy: 0.5678\n",
      "Label 1 Accuracy: 0.6475\n",
      "Label 2 Accuracy: 0.5748\n",
      "Epoch 106/120, Loss: 0.8540, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5666\n",
      "Label 1 Accuracy: 0.6475\n",
      "Label 2 Accuracy: 0.5762\n",
      "Epoch 107/120, Loss: 0.8537, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5678\n",
      "Label 1 Accuracy: 0.6483\n",
      "Label 2 Accuracy: 0.5741\n",
      "Epoch 108/120, Loss: 0.8539, Overall Accuracy: 0.5976\n",
      "Label 0 Accuracy: 0.5664\n",
      "Label 1 Accuracy: 0.6461\n",
      "Label 2 Accuracy: 0.5751\n",
      "Epoch 109/120, Loss: 0.8539, Overall Accuracy: 0.5982\n",
      "Label 0 Accuracy: 0.5688\n",
      "Label 1 Accuracy: 0.6472\n",
      "Label 2 Accuracy: 0.5735\n",
      "Epoch 110/120, Loss: 0.8539, Overall Accuracy: 0.5983\n",
      "Label 0 Accuracy: 0.5644\n",
      "Label 1 Accuracy: 0.6482\n",
      "Label 2 Accuracy: 0.5771\n",
      "Epoch 111/120, Loss: 0.8536, Overall Accuracy: 0.5977\n",
      "Label 0 Accuracy: 0.5651\n",
      "Label 1 Accuracy: 0.6478\n",
      "Label 2 Accuracy: 0.5750\n",
      "Epoch 112/120, Loss: 0.8537, Overall Accuracy: 0.5988\n",
      "Label 0 Accuracy: 0.5661\n",
      "Label 1 Accuracy: 0.6482\n",
      "Label 2 Accuracy: 0.5769\n",
      "Epoch 113/120, Loss: 0.8537, Overall Accuracy: 0.5996\n",
      "Label 0 Accuracy: 0.5650\n",
      "Label 1 Accuracy: 0.6512\n",
      "Label 2 Accuracy: 0.5770\n",
      "Epoch 114/120, Loss: 0.8537, Overall Accuracy: 0.5991\n",
      "Label 0 Accuracy: 0.5682\n",
      "Label 1 Accuracy: 0.6498\n",
      "Label 2 Accuracy: 0.5740\n",
      "Epoch 115/120, Loss: 0.8537, Overall Accuracy: 0.5990\n",
      "Label 0 Accuracy: 0.5681\n",
      "Label 1 Accuracy: 0.6496\n",
      "Label 2 Accuracy: 0.5739\n",
      "Epoch 116/120, Loss: 0.8535, Overall Accuracy: 0.5979\n",
      "Label 0 Accuracy: 0.5657\n",
      "Label 1 Accuracy: 0.6465\n",
      "Label 2 Accuracy: 0.5763\n",
      "Epoch 117/120, Loss: 0.8536, Overall Accuracy: 0.5972\n",
      "Label 0 Accuracy: 0.5641\n",
      "Label 1 Accuracy: 0.6461\n",
      "Label 2 Accuracy: 0.5762\n",
      "Epoch 118/120, Loss: 0.8533, Overall Accuracy: 0.5996\n",
      "Label 0 Accuracy: 0.5684\n",
      "Label 1 Accuracy: 0.6509\n",
      "Label 2 Accuracy: 0.5740\n",
      "Epoch 119/120, Loss: 0.8536, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5651\n",
      "Label 1 Accuracy: 0.6489\n",
      "Label 2 Accuracy: 0.5761\n",
      "Epoch 120/120, Loss: 0.8535, Overall Accuracy: 0.5985\n",
      "Label 0 Accuracy: 0.5655\n",
      "Label 1 Accuracy: 0.6476\n",
      "Label 2 Accuracy: 0.5770\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [00:52, 569.28it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [00:51, 577.58it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300001it [14:30, 344.70it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Loss: 0.8559, Overall Accuracy: 0.5993\n",
      "Label 0 Accuracy: 0.6209\n",
      "Label 1 Accuracy: 0.5986\n",
      "Label 2 Accuracy: 0.5769\n",
      "Epoch 2/120, Loss: 0.8239, Overall Accuracy: 0.6102\n",
      "Label 0 Accuracy: 0.6277\n",
      "Label 1 Accuracy: 0.6164\n",
      "Label 2 Accuracy: 0.5858\n",
      "Epoch 3/120, Loss: 0.8169, Overall Accuracy: 0.6125\n",
      "Label 0 Accuracy: 0.6320\n",
      "Label 1 Accuracy: 0.6158\n",
      "Label 2 Accuracy: 0.5887\n",
      "Epoch 4/120, Loss: 0.8126, Overall Accuracy: 0.6138\n",
      "Label 0 Accuracy: 0.6381\n",
      "Label 1 Accuracy: 0.6192\n",
      "Label 2 Accuracy: 0.5830\n",
      "Epoch 5/120, Loss: 0.8098, Overall Accuracy: 0.6152\n",
      "Label 0 Accuracy: 0.6376\n",
      "Label 1 Accuracy: 0.6206\n",
      "Label 2 Accuracy: 0.5862\n",
      "Epoch 6/120, Loss: 0.8070, Overall Accuracy: 0.6156\n",
      "Label 0 Accuracy: 0.6402\n",
      "Label 1 Accuracy: 0.6215\n",
      "Label 2 Accuracy: 0.5840\n",
      "Epoch 7/120, Loss: 0.8051, Overall Accuracy: 0.6179\n",
      "Label 0 Accuracy: 0.6444\n",
      "Label 1 Accuracy: 0.6224\n",
      "Label 2 Accuracy: 0.5856\n",
      "Epoch 8/120, Loss: 0.8033, Overall Accuracy: 0.6186\n",
      "Label 0 Accuracy: 0.6422\n",
      "Label 1 Accuracy: 0.6225\n",
      "Label 2 Accuracy: 0.5898\n",
      "Epoch 9/120, Loss: 0.8019, Overall Accuracy: 0.6191\n",
      "Label 0 Accuracy: 0.6441\n",
      "Label 1 Accuracy: 0.6231\n",
      "Label 2 Accuracy: 0.5888\n",
      "Epoch 10/120, Loss: 0.7998, Overall Accuracy: 0.6197\n",
      "Label 0 Accuracy: 0.6457\n",
      "Label 1 Accuracy: 0.6235\n",
      "Label 2 Accuracy: 0.5886\n",
      "Epoch 11/120, Loss: 0.7986, Overall Accuracy: 0.6205\n",
      "Label 0 Accuracy: 0.6451\n",
      "Label 1 Accuracy: 0.6235\n",
      "Label 2 Accuracy: 0.5914\n",
      "Epoch 12/120, Loss: 0.7977, Overall Accuracy: 0.6197\n",
      "Label 0 Accuracy: 0.6440\n",
      "Label 1 Accuracy: 0.6227\n",
      "Label 2 Accuracy: 0.5912\n",
      "Epoch 13/120, Loss: 0.7969, Overall Accuracy: 0.6204\n",
      "Label 0 Accuracy: 0.6417\n",
      "Label 1 Accuracy: 0.6227\n",
      "Label 2 Accuracy: 0.5957\n",
      "Epoch 14/120, Loss: 0.7957, Overall Accuracy: 0.6211\n",
      "Label 0 Accuracy: 0.6464\n",
      "Label 1 Accuracy: 0.6232\n",
      "Label 2 Accuracy: 0.5924\n",
      "Epoch 15/120, Loss: 0.7950, Overall Accuracy: 0.6216\n",
      "Label 0 Accuracy: 0.6423\n",
      "Label 1 Accuracy: 0.6253\n",
      "Label 2 Accuracy: 0.5961\n",
      "Epoch 16/120, Loss: 0.7945, Overall Accuracy: 0.6208\n",
      "Label 0 Accuracy: 0.6460\n",
      "Label 1 Accuracy: 0.6230\n",
      "Label 2 Accuracy: 0.5918\n",
      "Epoch 17/120, Loss: 0.7939, Overall Accuracy: 0.6225\n",
      "Label 0 Accuracy: 0.6451\n",
      "Label 1 Accuracy: 0.6267\n",
      "Label 2 Accuracy: 0.5947\n",
      "Epoch 18/120, Loss: 0.7932, Overall Accuracy: 0.6225\n",
      "Label 0 Accuracy: 0.6455\n",
      "Label 1 Accuracy: 0.6232\n",
      "Label 2 Accuracy: 0.5972\n",
      "Epoch 19/120, Loss: 0.7931, Overall Accuracy: 0.6224\n",
      "Label 0 Accuracy: 0.6466\n",
      "Label 1 Accuracy: 0.6273\n",
      "Label 2 Accuracy: 0.5920\n",
      "Epoch 20/120, Loss: 0.7929, Overall Accuracy: 0.6216\n",
      "Label 0 Accuracy: 0.6468\n",
      "Label 1 Accuracy: 0.6215\n",
      "Label 2 Accuracy: 0.5949\n",
      "Epoch 21/120, Loss: 0.7918, Overall Accuracy: 0.6234\n",
      "Label 0 Accuracy: 0.6445\n",
      "Label 1 Accuracy: 0.6272\n",
      "Label 2 Accuracy: 0.5974\n",
      "Epoch 22/120, Loss: 0.7918, Overall Accuracy: 0.6228\n",
      "Label 0 Accuracy: 0.6498\n",
      "Label 1 Accuracy: 0.6239\n",
      "Label 2 Accuracy: 0.5933\n",
      "Epoch 23/120, Loss: 0.7914, Overall Accuracy: 0.6225\n",
      "Label 0 Accuracy: 0.6462\n",
      "Label 1 Accuracy: 0.6230\n",
      "Label 2 Accuracy: 0.5969\n",
      "Epoch 24/120, Loss: 0.7907, Overall Accuracy: 0.6234\n",
      "Label 0 Accuracy: 0.6460\n",
      "Label 1 Accuracy: 0.6247\n",
      "Label 2 Accuracy: 0.5982\n",
      "Epoch 25/120, Loss: 0.7906, Overall Accuracy: 0.6236\n",
      "Label 0 Accuracy: 0.6505\n",
      "Label 1 Accuracy: 0.6255\n",
      "Label 2 Accuracy: 0.5932\n",
      "Epoch 26/120, Loss: 0.7908, Overall Accuracy: 0.6235\n",
      "Label 0 Accuracy: 0.6471\n",
      "Label 1 Accuracy: 0.6262\n",
      "Label 2 Accuracy: 0.5958\n",
      "Epoch 27/120, Loss: 0.7904, Overall Accuracy: 0.6247\n",
      "Label 0 Accuracy: 0.6496\n",
      "Label 1 Accuracy: 0.6261\n",
      "Label 2 Accuracy: 0.5968\n",
      "Epoch 28/120, Loss: 0.7903, Overall Accuracy: 0.6233\n",
      "Label 0 Accuracy: 0.6478\n",
      "Label 1 Accuracy: 0.6240\n",
      "Label 2 Accuracy: 0.5967\n",
      "Epoch 29/120, Loss: 0.7896, Overall Accuracy: 0.6245\n",
      "Label 0 Accuracy: 0.6496\n",
      "Label 1 Accuracy: 0.6262\n",
      "Label 2 Accuracy: 0.5963\n",
      "Epoch 30/120, Loss: 0.7897, Overall Accuracy: 0.6234\n",
      "Label 0 Accuracy: 0.6470\n",
      "Label 1 Accuracy: 0.6265\n",
      "Label 2 Accuracy: 0.5955\n",
      "Epoch 31/120, Loss: 0.7896, Overall Accuracy: 0.6225\n",
      "Label 0 Accuracy: 0.6468\n",
      "Label 1 Accuracy: 0.6253\n",
      "Label 2 Accuracy: 0.5942\n",
      "Epoch 32/120, Loss: 0.7893, Overall Accuracy: 0.6242\n",
      "Label 0 Accuracy: 0.6445\n",
      "Label 1 Accuracy: 0.6271\n",
      "Label 2 Accuracy: 0.5998\n",
      "Epoch 33/120, Loss: 0.7888, Overall Accuracy: 0.6229\n",
      "Label 0 Accuracy: 0.6495\n",
      "Label 1 Accuracy: 0.6247\n",
      "Label 2 Accuracy: 0.5930\n",
      "Epoch 34/120, Loss: 0.7891, Overall Accuracy: 0.6241\n",
      "Label 0 Accuracy: 0.6469\n",
      "Label 1 Accuracy: 0.6253\n",
      "Label 2 Accuracy: 0.5987\n",
      "Epoch 35/120, Loss: 0.7889, Overall Accuracy: 0.6239\n",
      "Label 0 Accuracy: 0.6451\n",
      "Label 1 Accuracy: 0.6258\n",
      "Label 2 Accuracy: 0.5997\n",
      "Epoch 36/120, Loss: 0.7885, Overall Accuracy: 0.6237\n",
      "Label 0 Accuracy: 0.6440\n",
      "Label 1 Accuracy: 0.6248\n",
      "Label 2 Accuracy: 0.6010\n",
      "Epoch 37/120, Loss: 0.7886, Overall Accuracy: 0.6238\n",
      "Label 0 Accuracy: 0.6474\n",
      "Label 1 Accuracy: 0.6269\n",
      "Label 2 Accuracy: 0.5957\n",
      "Epoch 38/120, Loss: 0.7881, Overall Accuracy: 0.6235\n",
      "Label 0 Accuracy: 0.6462\n",
      "Label 1 Accuracy: 0.6243\n",
      "Label 2 Accuracy: 0.5985\n",
      "Epoch 39/120, Loss: 0.7881, Overall Accuracy: 0.6233\n",
      "Label 0 Accuracy: 0.6485\n",
      "Label 1 Accuracy: 0.6229\n",
      "Label 2 Accuracy: 0.5968\n",
      "Epoch 40/120, Loss: 0.7879, Overall Accuracy: 0.6239\n",
      "Label 0 Accuracy: 0.6460\n",
      "Label 1 Accuracy: 0.6252\n",
      "Label 2 Accuracy: 0.5991\n",
      "Epoch 41/120, Loss: 0.7880, Overall Accuracy: 0.6237\n",
      "Label 0 Accuracy: 0.6467\n",
      "Label 1 Accuracy: 0.6257\n",
      "Label 2 Accuracy: 0.5975\n",
      "Epoch 42/120, Loss: 0.7877, Overall Accuracy: 0.6242\n",
      "Label 0 Accuracy: 0.6476\n",
      "Label 1 Accuracy: 0.6249\n",
      "Label 2 Accuracy: 0.5987\n",
      "Epoch 43/120, Loss: 0.7874, Overall Accuracy: 0.6238\n",
      "Label 0 Accuracy: 0.6444\n",
      "Label 1 Accuracy: 0.6281\n",
      "Label 2 Accuracy: 0.5981\n",
      "Epoch 44/120, Loss: 0.7874, Overall Accuracy: 0.6245\n",
      "Label 0 Accuracy: 0.6490\n",
      "Label 1 Accuracy: 0.6267\n",
      "Label 2 Accuracy: 0.5965\n",
      "Epoch 45/120, Loss: 0.7876, Overall Accuracy: 0.6247\n",
      "Label 0 Accuracy: 0.6487\n",
      "Label 1 Accuracy: 0.6257\n",
      "Label 2 Accuracy: 0.5982\n",
      "Epoch 46/120, Loss: 0.7870, Overall Accuracy: 0.6237\n",
      "Label 0 Accuracy: 0.6466\n",
      "Label 1 Accuracy: 0.6246\n",
      "Label 2 Accuracy: 0.5986\n",
      "Epoch 47/120, Loss: 0.7872, Overall Accuracy: 0.6249\n",
      "Label 0 Accuracy: 0.6483\n",
      "Label 1 Accuracy: 0.6265\n",
      "Label 2 Accuracy: 0.5985\n",
      "Epoch 48/120, Loss: 0.7872, Overall Accuracy: 0.6246\n",
      "Label 0 Accuracy: 0.6443\n",
      "Label 1 Accuracy: 0.6252\n",
      "Label 2 Accuracy: 0.6031\n",
      "Epoch 49/120, Loss: 0.7870, Overall Accuracy: 0.6250\n",
      "Label 0 Accuracy: 0.6459\n",
      "Label 1 Accuracy: 0.6279\n",
      "Label 2 Accuracy: 0.6001\n",
      "Epoch 50/120, Loss: 0.7870, Overall Accuracy: 0.6248\n",
      "Label 0 Accuracy: 0.6470\n",
      "Label 1 Accuracy: 0.6269\n",
      "Label 2 Accuracy: 0.5993\n",
      "Epoch 51/120, Loss: 0.7866, Overall Accuracy: 0.6246\n",
      "Label 0 Accuracy: 0.6470\n",
      "Label 1 Accuracy: 0.6251\n",
      "Label 2 Accuracy: 0.6003\n",
      "Epoch 52/120, Loss: 0.7866, Overall Accuracy: 0.6245\n",
      "Label 0 Accuracy: 0.6465\n",
      "Label 1 Accuracy: 0.6241\n",
      "Label 2 Accuracy: 0.6014\n",
      "Epoch 53/120, Loss: 0.7867, Overall Accuracy: 0.6240\n",
      "Label 0 Accuracy: 0.6471\n",
      "Label 1 Accuracy: 0.6246\n",
      "Label 2 Accuracy: 0.5989\n",
      "Epoch 54/120, Loss: 0.7862, Overall Accuracy: 0.6261\n",
      "Label 0 Accuracy: 0.6463\n",
      "Label 1 Accuracy: 0.6300\n",
      "Label 2 Accuracy: 0.6009\n",
      "Epoch 55/120, Loss: 0.7865, Overall Accuracy: 0.6237\n",
      "Label 0 Accuracy: 0.6464\n",
      "Label 1 Accuracy: 0.6239\n",
      "Label 2 Accuracy: 0.5995\n",
      "Epoch 56/120, Loss: 0.7863, Overall Accuracy: 0.6242\n",
      "Label 0 Accuracy: 0.6452\n",
      "Label 1 Accuracy: 0.6268\n",
      "Label 2 Accuracy: 0.5995\n",
      "Epoch 57/120, Loss: 0.7860, Overall Accuracy: 0.6253\n",
      "Label 0 Accuracy: 0.6483\n",
      "Label 1 Accuracy: 0.6271\n",
      "Label 2 Accuracy: 0.5991\n",
      "Epoch 58/120, Loss: 0.7862, Overall Accuracy: 0.6240\n",
      "Label 0 Accuracy: 0.6444\n",
      "Label 1 Accuracy: 0.6260\n",
      "Label 2 Accuracy: 0.6004\n",
      "Epoch 59/120, Loss: 0.7861, Overall Accuracy: 0.6241\n",
      "Label 0 Accuracy: 0.6445\n",
      "Label 1 Accuracy: 0.6250\n",
      "Label 2 Accuracy: 0.6017\n",
      "Epoch 60/120, Loss: 0.7855, Overall Accuracy: 0.6257\n",
      "Label 0 Accuracy: 0.6446\n",
      "Label 1 Accuracy: 0.6286\n",
      "Label 2 Accuracy: 0.6030\n",
      "Epoch 61/120, Loss: 0.7861, Overall Accuracy: 0.6260\n",
      "Label 0 Accuracy: 0.6472\n",
      "Label 1 Accuracy: 0.6279\n",
      "Label 2 Accuracy: 0.6017\n",
      "Epoch 62/120, Loss: 0.7856, Overall Accuracy: 0.6257\n",
      "Label 0 Accuracy: 0.6469\n",
      "Label 1 Accuracy: 0.6288\n",
      "Label 2 Accuracy: 0.6002\n",
      "Epoch 63/120, Loss: 0.7857, Overall Accuracy: 0.6249\n",
      "Label 0 Accuracy: 0.6438\n",
      "Label 1 Accuracy: 0.6262\n",
      "Label 2 Accuracy: 0.6037\n",
      "Epoch 64/120, Loss: 0.7856, Overall Accuracy: 0.6250\n",
      "Label 0 Accuracy: 0.6425\n",
      "Label 1 Accuracy: 0.6275\n",
      "Label 2 Accuracy: 0.6041\n",
      "Epoch 65/120, Loss: 0.7859, Overall Accuracy: 0.6245\n",
      "Label 0 Accuracy: 0.6451\n",
      "Label 1 Accuracy: 0.6278\n",
      "Label 2 Accuracy: 0.5994\n",
      "Epoch 66/120, Loss: 0.7855, Overall Accuracy: 0.6252\n",
      "Label 0 Accuracy: 0.6445\n",
      "Label 1 Accuracy: 0.6283\n",
      "Label 2 Accuracy: 0.6018\n",
      "Epoch 67/120, Loss: 0.7856, Overall Accuracy: 0.6252\n",
      "Label 0 Accuracy: 0.6451\n",
      "Label 1 Accuracy: 0.6283\n",
      "Label 2 Accuracy: 0.6010\n",
      "Epoch 68/120, Loss: 0.7854, Overall Accuracy: 0.6255\n",
      "Label 0 Accuracy: 0.6457\n",
      "Label 1 Accuracy: 0.6283\n",
      "Label 2 Accuracy: 0.6014\n",
      "Epoch 69/120, Loss: 0.7854, Overall Accuracy: 0.6258\n",
      "Label 0 Accuracy: 0.6455\n",
      "Label 1 Accuracy: 0.6293\n",
      "Label 2 Accuracy: 0.6016\n",
      "Epoch 70/120, Loss: 0.7853, Overall Accuracy: 0.6262\n",
      "Label 0 Accuracy: 0.6478\n",
      "Label 1 Accuracy: 0.6290\n",
      "Label 2 Accuracy: 0.6007\n",
      "Epoch 71/120, Loss: 0.7851, Overall Accuracy: 0.6257\n",
      "Label 0 Accuracy: 0.6479\n",
      "Label 1 Accuracy: 0.6300\n",
      "Label 2 Accuracy: 0.5981\n",
      "Epoch 72/120, Loss: 0.7849, Overall Accuracy: 0.6252\n",
      "Label 0 Accuracy: 0.6452\n",
      "Label 1 Accuracy: 0.6263\n",
      "Label 2 Accuracy: 0.6027\n",
      "Epoch 73/120, Loss: 0.7851, Overall Accuracy: 0.6266\n",
      "Label 0 Accuracy: 0.6486\n",
      "Label 1 Accuracy: 0.6321\n",
      "Label 2 Accuracy: 0.5982\n",
      "Epoch 74/120, Loss: 0.7847, Overall Accuracy: 0.6262\n",
      "Label 0 Accuracy: 0.6479\n",
      "Label 1 Accuracy: 0.6300\n",
      "Label 2 Accuracy: 0.5997\n",
      "Epoch 75/120, Loss: 0.7850, Overall Accuracy: 0.6265\n",
      "Label 0 Accuracy: 0.6465\n",
      "Label 1 Accuracy: 0.6311\n",
      "Label 2 Accuracy: 0.6009\n",
      "Epoch 76/120, Loss: 0.7851, Overall Accuracy: 0.6253\n",
      "Label 0 Accuracy: 0.6457\n",
      "Label 1 Accuracy: 0.6280\n",
      "Label 2 Accuracy: 0.6011\n",
      "Epoch 77/120, Loss: 0.7849, Overall Accuracy: 0.6252\n",
      "Label 0 Accuracy: 0.6444\n",
      "Label 1 Accuracy: 0.6281\n",
      "Label 2 Accuracy: 0.6020\n",
      "Epoch 78/120, Loss: 0.7848, Overall Accuracy: 0.6263\n",
      "Label 0 Accuracy: 0.6476\n",
      "Label 1 Accuracy: 0.6317\n",
      "Label 2 Accuracy: 0.5984\n",
      "Epoch 79/120, Loss: 0.7849, Overall Accuracy: 0.6246\n",
      "Label 0 Accuracy: 0.6455\n",
      "Label 1 Accuracy: 0.6253\n",
      "Label 2 Accuracy: 0.6019\n",
      "Epoch 80/120, Loss: 0.7848, Overall Accuracy: 0.6259\n",
      "Label 0 Accuracy: 0.6452\n",
      "Label 1 Accuracy: 0.6301\n",
      "Label 2 Accuracy: 0.6014\n",
      "Epoch 81/120, Loss: 0.7782, Overall Accuracy: 0.6283\n",
      "Label 0 Accuracy: 0.6499\n",
      "Label 1 Accuracy: 0.6292\n",
      "Label 2 Accuracy: 0.6047\n",
      "Epoch 82/120, Loss: 0.7775, Overall Accuracy: 0.6292\n",
      "Label 0 Accuracy: 0.6501\n",
      "Label 1 Accuracy: 0.6313\n",
      "Label 2 Accuracy: 0.6050\n",
      "Epoch 83/120, Loss: 0.7773, Overall Accuracy: 0.6292\n",
      "Label 0 Accuracy: 0.6514\n",
      "Label 1 Accuracy: 0.6306\n",
      "Label 2 Accuracy: 0.6043\n",
      "Epoch 84/120, Loss: 0.7775, Overall Accuracy: 0.6285\n",
      "Label 0 Accuracy: 0.6493\n",
      "Label 1 Accuracy: 0.6300\n",
      "Label 2 Accuracy: 0.6051\n",
      "Epoch 85/120, Loss: 0.7771, Overall Accuracy: 0.6293\n",
      "Label 0 Accuracy: 0.6512\n",
      "Label 1 Accuracy: 0.6316\n",
      "Label 2 Accuracy: 0.6039\n",
      "Epoch 86/120, Loss: 0.7773, Overall Accuracy: 0.6299\n",
      "Label 0 Accuracy: 0.6487\n",
      "Label 1 Accuracy: 0.6330\n",
      "Label 2 Accuracy: 0.6071\n",
      "Epoch 87/120, Loss: 0.7770, Overall Accuracy: 0.6304\n",
      "Label 0 Accuracy: 0.6493\n",
      "Label 1 Accuracy: 0.6335\n",
      "Label 2 Accuracy: 0.6074\n",
      "Epoch 88/120, Loss: 0.7769, Overall Accuracy: 0.6293\n",
      "Label 0 Accuracy: 0.6496\n",
      "Label 1 Accuracy: 0.6320\n",
      "Label 2 Accuracy: 0.6053\n",
      "Epoch 89/120, Loss: 0.7771, Overall Accuracy: 0.6293\n",
      "Label 0 Accuracy: 0.6492\n",
      "Label 1 Accuracy: 0.6314\n",
      "Label 2 Accuracy: 0.6061\n",
      "Epoch 90/120, Loss: 0.7768, Overall Accuracy: 0.6297\n",
      "Label 0 Accuracy: 0.6498\n",
      "Label 1 Accuracy: 0.6303\n",
      "Label 2 Accuracy: 0.6078\n",
      "Epoch 91/120, Loss: 0.7767, Overall Accuracy: 0.6301\n",
      "Label 0 Accuracy: 0.6494\n",
      "Label 1 Accuracy: 0.6345\n",
      "Label 2 Accuracy: 0.6055\n",
      "Epoch 92/120, Loss: 0.7767, Overall Accuracy: 0.6294\n",
      "Label 0 Accuracy: 0.6500\n",
      "Label 1 Accuracy: 0.6315\n",
      "Label 2 Accuracy: 0.6055\n",
      "Epoch 93/120, Loss: 0.7767, Overall Accuracy: 0.6299\n",
      "Label 0 Accuracy: 0.6527\n",
      "Label 1 Accuracy: 0.6316\n",
      "Label 2 Accuracy: 0.6040\n",
      "Epoch 94/120, Loss: 0.7765, Overall Accuracy: 0.6305\n",
      "Label 0 Accuracy: 0.6487\n",
      "Label 1 Accuracy: 0.6338\n",
      "Label 2 Accuracy: 0.6081\n",
      "Epoch 95/120, Loss: 0.7765, Overall Accuracy: 0.6300\n",
      "Label 0 Accuracy: 0.6487\n",
      "Label 1 Accuracy: 0.6325\n",
      "Label 2 Accuracy: 0.6077\n",
      "Epoch 96/120, Loss: 0.7769, Overall Accuracy: 0.6301\n",
      "Label 0 Accuracy: 0.6512\n",
      "Label 1 Accuracy: 0.6325\n",
      "Label 2 Accuracy: 0.6053\n",
      "Epoch 97/120, Loss: 0.7767, Overall Accuracy: 0.6296\n",
      "Label 0 Accuracy: 0.6504\n",
      "Label 1 Accuracy: 0.6310\n",
      "Label 2 Accuracy: 0.6061\n",
      "Epoch 98/120, Loss: 0.7764, Overall Accuracy: 0.6302\n",
      "Label 0 Accuracy: 0.6507\n",
      "Label 1 Accuracy: 0.6324\n",
      "Label 2 Accuracy: 0.6062\n",
      "Epoch 99/120, Loss: 0.7767, Overall Accuracy: 0.6306\n",
      "Label 0 Accuracy: 0.6499\n",
      "Label 1 Accuracy: 0.6334\n",
      "Label 2 Accuracy: 0.6074\n",
      "Epoch 100/120, Loss: 0.7764, Overall Accuracy: 0.6310\n",
      "Label 0 Accuracy: 0.6500\n",
      "Label 1 Accuracy: 0.6327\n",
      "Label 2 Accuracy: 0.6092\n",
      "Epoch 101/120, Loss: 0.7765, Overall Accuracy: 0.6309\n",
      "Label 0 Accuracy: 0.6513\n",
      "Label 1 Accuracy: 0.6332\n",
      "Label 2 Accuracy: 0.6071\n",
      "Epoch 102/120, Loss: 0.7763, Overall Accuracy: 0.6302\n",
      "Label 0 Accuracy: 0.6495\n",
      "Label 1 Accuracy: 0.6337\n",
      "Label 2 Accuracy: 0.6063\n",
      "Epoch 103/120, Loss: 0.7762, Overall Accuracy: 0.6297\n",
      "Label 0 Accuracy: 0.6508\n",
      "Label 1 Accuracy: 0.6330\n",
      "Label 2 Accuracy: 0.6041\n",
      "Epoch 104/120, Loss: 0.7764, Overall Accuracy: 0.6293\n",
      "Label 0 Accuracy: 0.6522\n",
      "Label 1 Accuracy: 0.6305\n",
      "Label 2 Accuracy: 0.6038\n",
      "Epoch 105/120, Loss: 0.7762, Overall Accuracy: 0.6292\n",
      "Label 0 Accuracy: 0.6509\n",
      "Label 1 Accuracy: 0.6311\n",
      "Label 2 Accuracy: 0.6043\n",
      "Epoch 106/120, Loss: 0.7763, Overall Accuracy: 0.6297\n",
      "Label 0 Accuracy: 0.6518\n",
      "Label 1 Accuracy: 0.6315\n",
      "Label 2 Accuracy: 0.6046\n",
      "Epoch 107/120, Loss: 0.7762, Overall Accuracy: 0.6306\n",
      "Label 0 Accuracy: 0.6510\n",
      "Label 1 Accuracy: 0.6323\n",
      "Label 2 Accuracy: 0.6071\n",
      "Epoch 108/120, Loss: 0.7762, Overall Accuracy: 0.6306\n",
      "Label 0 Accuracy: 0.6533\n",
      "Label 1 Accuracy: 0.6328\n",
      "Label 2 Accuracy: 0.6043\n",
      "Epoch 109/120, Loss: 0.7760, Overall Accuracy: 0.6311\n",
      "Label 0 Accuracy: 0.6508\n",
      "Label 1 Accuracy: 0.6345\n",
      "Label 2 Accuracy: 0.6069\n",
      "Epoch 110/120, Loss: 0.7761, Overall Accuracy: 0.6303\n",
      "Label 0 Accuracy: 0.6534\n",
      "Label 1 Accuracy: 0.6322\n",
      "Label 2 Accuracy: 0.6038\n",
      "Epoch 111/120, Loss: 0.7762, Overall Accuracy: 0.6303\n",
      "Label 0 Accuracy: 0.6519\n",
      "Label 1 Accuracy: 0.6333\n",
      "Label 2 Accuracy: 0.6046\n",
      "Epoch 112/120, Loss: 0.7762, Overall Accuracy: 0.6301\n",
      "Label 0 Accuracy: 0.6510\n",
      "Label 1 Accuracy: 0.6313\n",
      "Label 2 Accuracy: 0.6067\n",
      "Epoch 113/120, Loss: 0.7760, Overall Accuracy: 0.6303\n",
      "Label 0 Accuracy: 0.6509\n",
      "Label 1 Accuracy: 0.6336\n",
      "Label 2 Accuracy: 0.6053\n",
      "Epoch 114/120, Loss: 0.7759, Overall Accuracy: 0.6314\n",
      "Label 0 Accuracy: 0.6517\n",
      "Label 1 Accuracy: 0.6345\n",
      "Label 2 Accuracy: 0.6068\n",
      "Epoch 115/120, Loss: 0.7758, Overall Accuracy: 0.6306\n",
      "Label 0 Accuracy: 0.6520\n",
      "Label 1 Accuracy: 0.6328\n",
      "Label 2 Accuracy: 0.6057\n",
      "Epoch 116/120, Loss: 0.7762, Overall Accuracy: 0.6305\n",
      "Label 0 Accuracy: 0.6490\n",
      "Label 1 Accuracy: 0.6324\n",
      "Label 2 Accuracy: 0.6090\n",
      "Epoch 117/120, Loss: 0.7759, Overall Accuracy: 0.6303\n",
      "Label 0 Accuracy: 0.6527\n",
      "Label 1 Accuracy: 0.6331\n",
      "Label 2 Accuracy: 0.6040\n",
      "Epoch 118/120, Loss: 0.7760, Overall Accuracy: 0.6304\n",
      "Label 0 Accuracy: 0.6505\n",
      "Label 1 Accuracy: 0.6340\n",
      "Label 2 Accuracy: 0.6059\n",
      "Epoch 119/120, Loss: 0.7759, Overall Accuracy: 0.6305\n",
      "Label 0 Accuracy: 0.6507\n",
      "Label 1 Accuracy: 0.6318\n",
      "Label 2 Accuracy: 0.6077\n",
      "Epoch 120/120, Loss: 0.7758, Overall Accuracy: 0.6302\n",
      "Label 0 Accuracy: 0.6512\n",
      "Label 1 Accuracy: 0.6339\n",
      "Label 2 Accuracy: 0.6044\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [01:27, 340.99it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [01:28, 338.96it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300001it [22:09, 225.73it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Loss: 0.9361, Overall Accuracy: 0.5597\n",
      "Label 0 Accuracy: 0.7147\n",
      "Label 1 Accuracy: 0.5400\n",
      "Label 2 Accuracy: 0.3759\n",
      "Epoch 2/120, Loss: 0.9012, Overall Accuracy: 0.5720\n",
      "Label 0 Accuracy: 0.7250\n",
      "Label 1 Accuracy: 0.5570\n",
      "Label 2 Accuracy: 0.3855\n",
      "Epoch 3/120, Loss: 0.8928, Overall Accuracy: 0.5757\n",
      "Label 0 Accuracy: 0.7330\n",
      "Label 1 Accuracy: 0.5621\n",
      "Label 2 Accuracy: 0.3818\n",
      "Epoch 4/120, Loss: 0.8874, Overall Accuracy: 0.5772\n",
      "Label 0 Accuracy: 0.7313\n",
      "Label 1 Accuracy: 0.5618\n",
      "Label 2 Accuracy: 0.3897\n",
      "Epoch 5/120, Loss: 0.8840, Overall Accuracy: 0.5778\n",
      "Label 0 Accuracy: 0.7322\n",
      "Label 1 Accuracy: 0.5607\n",
      "Label 2 Accuracy: 0.3918\n",
      "Epoch 6/120, Loss: 0.8810, Overall Accuracy: 0.5779\n",
      "Label 0 Accuracy: 0.7318\n",
      "Label 1 Accuracy: 0.5584\n",
      "Label 2 Accuracy: 0.3953\n",
      "Epoch 7/120, Loss: 0.8788, Overall Accuracy: 0.5790\n",
      "Label 0 Accuracy: 0.7342\n",
      "Label 1 Accuracy: 0.5598\n",
      "Label 2 Accuracy: 0.3941\n",
      "Epoch 8/120, Loss: 0.8767, Overall Accuracy: 0.5787\n",
      "Label 0 Accuracy: 0.7323\n",
      "Label 1 Accuracy: 0.5572\n",
      "Label 2 Accuracy: 0.3989\n",
      "Epoch 9/120, Loss: 0.8751, Overall Accuracy: 0.5796\n",
      "Label 0 Accuracy: 0.7316\n",
      "Label 1 Accuracy: 0.5592\n",
      "Label 2 Accuracy: 0.4005\n",
      "Epoch 10/120, Loss: 0.8737, Overall Accuracy: 0.5796\n",
      "Label 0 Accuracy: 0.7297\n",
      "Label 1 Accuracy: 0.5589\n",
      "Label 2 Accuracy: 0.4035\n",
      "Epoch 11/120, Loss: 0.8728, Overall Accuracy: 0.5800\n",
      "Label 0 Accuracy: 0.7345\n",
      "Label 1 Accuracy: 0.5574\n",
      "Label 2 Accuracy: 0.4001\n",
      "Epoch 12/120, Loss: 0.8713, Overall Accuracy: 0.5828\n",
      "Label 0 Accuracy: 0.7358\n",
      "Label 1 Accuracy: 0.5622\n",
      "Label 2 Accuracy: 0.4027\n",
      "Epoch 13/120, Loss: 0.8702, Overall Accuracy: 0.5814\n",
      "Label 0 Accuracy: 0.7292\n",
      "Label 1 Accuracy: 0.5614\n",
      "Label 2 Accuracy: 0.4076\n",
      "Epoch 14/120, Loss: 0.8693, Overall Accuracy: 0.5837\n",
      "Label 0 Accuracy: 0.7339\n",
      "Label 1 Accuracy: 0.5640\n",
      "Label 2 Accuracy: 0.4061\n",
      "Epoch 15/120, Loss: 0.8683, Overall Accuracy: 0.5823\n",
      "Label 0 Accuracy: 0.7336\n",
      "Label 1 Accuracy: 0.5622\n",
      "Label 2 Accuracy: 0.4038\n",
      "Epoch 16/120, Loss: 0.8679, Overall Accuracy: 0.5833\n",
      "Label 0 Accuracy: 0.7326\n",
      "Label 1 Accuracy: 0.5654\n",
      "Label 2 Accuracy: 0.4048\n",
      "Epoch 17/120, Loss: 0.8671, Overall Accuracy: 0.5829\n",
      "Label 0 Accuracy: 0.7299\n",
      "Label 1 Accuracy: 0.5615\n",
      "Label 2 Accuracy: 0.4118\n",
      "Epoch 18/120, Loss: 0.8661, Overall Accuracy: 0.5834\n",
      "Label 0 Accuracy: 0.7304\n",
      "Label 1 Accuracy: 0.5630\n",
      "Label 2 Accuracy: 0.4110\n",
      "Epoch 19/120, Loss: 0.8657, Overall Accuracy: 0.5824\n",
      "Label 0 Accuracy: 0.7334\n",
      "Label 1 Accuracy: 0.5597\n",
      "Label 2 Accuracy: 0.4074\n",
      "Epoch 20/120, Loss: 0.8656, Overall Accuracy: 0.5836\n",
      "Label 0 Accuracy: 0.7301\n",
      "Label 1 Accuracy: 0.5637\n",
      "Label 2 Accuracy: 0.4115\n",
      "Epoch 21/120, Loss: 0.8651, Overall Accuracy: 0.5842\n",
      "Label 0 Accuracy: 0.7328\n",
      "Label 1 Accuracy: 0.5624\n",
      "Label 2 Accuracy: 0.4115\n",
      "Epoch 22/120, Loss: 0.8645, Overall Accuracy: 0.5846\n",
      "Label 0 Accuracy: 0.7294\n",
      "Label 1 Accuracy: 0.5646\n",
      "Label 2 Accuracy: 0.4147\n",
      "Epoch 23/120, Loss: 0.8640, Overall Accuracy: 0.5843\n",
      "Label 0 Accuracy: 0.7319\n",
      "Label 1 Accuracy: 0.5641\n",
      "Label 2 Accuracy: 0.4110\n",
      "Epoch 24/120, Loss: 0.8637, Overall Accuracy: 0.5848\n",
      "Label 0 Accuracy: 0.7310\n",
      "Label 1 Accuracy: 0.5620\n",
      "Label 2 Accuracy: 0.4162\n",
      "Epoch 25/120, Loss: 0.8632, Overall Accuracy: 0.5851\n",
      "Label 0 Accuracy: 0.7342\n",
      "Label 1 Accuracy: 0.5644\n",
      "Label 2 Accuracy: 0.4103\n",
      "Epoch 26/120, Loss: 0.8630, Overall Accuracy: 0.5846\n",
      "Label 0 Accuracy: 0.7324\n",
      "Label 1 Accuracy: 0.5628\n",
      "Label 2 Accuracy: 0.4128\n",
      "Epoch 27/120, Loss: 0.8629, Overall Accuracy: 0.5849\n",
      "Label 0 Accuracy: 0.7341\n",
      "Label 1 Accuracy: 0.5631\n",
      "Label 2 Accuracy: 0.4113\n",
      "Epoch 28/120, Loss: 0.8624, Overall Accuracy: 0.5850\n",
      "Label 0 Accuracy: 0.7342\n",
      "Label 1 Accuracy: 0.5629\n",
      "Label 2 Accuracy: 0.4115\n",
      "Epoch 29/120, Loss: 0.8616, Overall Accuracy: 0.5856\n",
      "Label 0 Accuracy: 0.7315\n",
      "Label 1 Accuracy: 0.5639\n",
      "Label 2 Accuracy: 0.4163\n",
      "Epoch 30/120, Loss: 0.8618, Overall Accuracy: 0.5850\n",
      "Label 0 Accuracy: 0.7318\n",
      "Label 1 Accuracy: 0.5641\n",
      "Label 2 Accuracy: 0.4136\n",
      "Epoch 31/120, Loss: 0.8617, Overall Accuracy: 0.5859\n",
      "Label 0 Accuracy: 0.7327\n",
      "Label 1 Accuracy: 0.5664\n",
      "Label 2 Accuracy: 0.4128\n",
      "Epoch 32/120, Loss: 0.8611, Overall Accuracy: 0.5847\n",
      "Label 0 Accuracy: 0.7307\n",
      "Label 1 Accuracy: 0.5634\n",
      "Label 2 Accuracy: 0.4146\n",
      "Epoch 33/120, Loss: 0.8608, Overall Accuracy: 0.5867\n",
      "Label 0 Accuracy: 0.7309\n",
      "Label 1 Accuracy: 0.5692\n",
      "Label 2 Accuracy: 0.4147\n",
      "Epoch 34/120, Loss: 0.8606, Overall Accuracy: 0.5861\n",
      "Label 0 Accuracy: 0.7300\n",
      "Label 1 Accuracy: 0.5655\n",
      "Label 2 Accuracy: 0.4183\n",
      "Epoch 35/120, Loss: 0.8606, Overall Accuracy: 0.5856\n",
      "Label 0 Accuracy: 0.7329\n",
      "Label 1 Accuracy: 0.5637\n",
      "Label 2 Accuracy: 0.4145\n",
      "Epoch 36/120, Loss: 0.8603, Overall Accuracy: 0.5846\n",
      "Label 0 Accuracy: 0.7292\n",
      "Label 1 Accuracy: 0.5625\n",
      "Label 2 Accuracy: 0.4175\n",
      "Epoch 37/120, Loss: 0.8601, Overall Accuracy: 0.5869\n",
      "Label 0 Accuracy: 0.7328\n",
      "Label 1 Accuracy: 0.5659\n",
      "Label 2 Accuracy: 0.4166\n",
      "Epoch 38/120, Loss: 0.8599, Overall Accuracy: 0.5863\n",
      "Label 0 Accuracy: 0.7312\n",
      "Label 1 Accuracy: 0.5655\n",
      "Label 2 Accuracy: 0.4172\n",
      "Epoch 39/120, Loss: 0.8595, Overall Accuracy: 0.5865\n",
      "Label 0 Accuracy: 0.7328\n",
      "Label 1 Accuracy: 0.5670\n",
      "Label 2 Accuracy: 0.4141\n",
      "Epoch 40/120, Loss: 0.8593, Overall Accuracy: 0.5866\n",
      "Label 0 Accuracy: 0.7308\n",
      "Label 1 Accuracy: 0.5656\n",
      "Label 2 Accuracy: 0.4186\n",
      "Epoch 41/120, Loss: 0.8594, Overall Accuracy: 0.5867\n",
      "Label 0 Accuracy: 0.7307\n",
      "Label 1 Accuracy: 0.5678\n",
      "Label 2 Accuracy: 0.4166\n",
      "Epoch 42/120, Loss: 0.8590, Overall Accuracy: 0.5871\n",
      "Label 0 Accuracy: 0.7302\n",
      "Label 1 Accuracy: 0.5667\n",
      "Label 2 Accuracy: 0.4198\n",
      "Epoch 43/120, Loss: 0.8588, Overall Accuracy: 0.5862\n",
      "Label 0 Accuracy: 0.7330\n",
      "Label 1 Accuracy: 0.5657\n",
      "Label 2 Accuracy: 0.4141\n",
      "Epoch 44/120, Loss: 0.8587, Overall Accuracy: 0.5880\n",
      "Label 0 Accuracy: 0.7326\n",
      "Label 1 Accuracy: 0.5695\n",
      "Label 2 Accuracy: 0.4167\n",
      "Epoch 45/120, Loss: 0.8587, Overall Accuracy: 0.5865\n",
      "Label 0 Accuracy: 0.7317\n",
      "Label 1 Accuracy: 0.5657\n",
      "Label 2 Accuracy: 0.4169\n",
      "Epoch 46/120, Loss: 0.8588, Overall Accuracy: 0.5869\n",
      "Label 0 Accuracy: 0.7345\n",
      "Label 1 Accuracy: 0.5672\n",
      "Label 2 Accuracy: 0.4129\n",
      "Epoch 47/120, Loss: 0.8586, Overall Accuracy: 0.5879\n",
      "Label 0 Accuracy: 0.7340\n",
      "Label 1 Accuracy: 0.5684\n",
      "Label 2 Accuracy: 0.4158\n",
      "Epoch 48/120, Loss: 0.8581, Overall Accuracy: 0.5875\n",
      "Label 0 Accuracy: 0.7328\n",
      "Label 1 Accuracy: 0.5677\n",
      "Label 2 Accuracy: 0.4165\n",
      "Epoch 49/120, Loss: 0.8576, Overall Accuracy: 0.5874\n",
      "Label 0 Accuracy: 0.7339\n",
      "Label 1 Accuracy: 0.5666\n",
      "Label 2 Accuracy: 0.4162\n",
      "Epoch 50/120, Loss: 0.8574, Overall Accuracy: 0.5880\n",
      "Label 0 Accuracy: 0.7338\n",
      "Label 1 Accuracy: 0.5667\n",
      "Label 2 Accuracy: 0.4185\n",
      "Epoch 51/120, Loss: 0.8572, Overall Accuracy: 0.5879\n",
      "Label 0 Accuracy: 0.7340\n",
      "Label 1 Accuracy: 0.5661\n",
      "Label 2 Accuracy: 0.4184\n",
      "Epoch 52/120, Loss: 0.8575, Overall Accuracy: 0.5881\n",
      "Label 0 Accuracy: 0.7324\n",
      "Label 1 Accuracy: 0.5679\n",
      "Label 2 Accuracy: 0.4191\n",
      "Epoch 53/120, Loss: 0.8574, Overall Accuracy: 0.5862\n",
      "Label 0 Accuracy: 0.7334\n",
      "Label 1 Accuracy: 0.5635\n",
      "Label 2 Accuracy: 0.4161\n",
      "Epoch 54/120, Loss: 0.8573, Overall Accuracy: 0.5879\n",
      "Label 0 Accuracy: 0.7352\n",
      "Label 1 Accuracy: 0.5669\n",
      "Label 2 Accuracy: 0.4157\n",
      "Epoch 55/120, Loss: 0.8574, Overall Accuracy: 0.5871\n",
      "Label 0 Accuracy: 0.7338\n",
      "Label 1 Accuracy: 0.5674\n",
      "Label 2 Accuracy: 0.4145\n",
      "Epoch 56/120, Loss: 0.8569, Overall Accuracy: 0.5878\n",
      "Label 0 Accuracy: 0.7352\n",
      "Label 1 Accuracy: 0.5654\n",
      "Label 2 Accuracy: 0.4170\n",
      "Epoch 57/120, Loss: 0.8568, Overall Accuracy: 0.5870\n",
      "Label 0 Accuracy: 0.7341\n",
      "Label 1 Accuracy: 0.5643\n",
      "Label 2 Accuracy: 0.4170\n",
      "Epoch 58/120, Loss: 0.8567, Overall Accuracy: 0.5871\n",
      "Label 0 Accuracy: 0.7336\n",
      "Label 1 Accuracy: 0.5656\n",
      "Label 2 Accuracy: 0.4166\n",
      "Epoch 59/120, Loss: 0.8566, Overall Accuracy: 0.5885\n",
      "Label 0 Accuracy: 0.7320\n",
      "Label 1 Accuracy: 0.5669\n",
      "Label 2 Accuracy: 0.4220\n",
      "Epoch 60/120, Loss: 0.8562, Overall Accuracy: 0.5884\n",
      "Label 0 Accuracy: 0.7338\n",
      "Label 1 Accuracy: 0.5682\n",
      "Label 2 Accuracy: 0.4178\n",
      "Epoch 61/120, Loss: 0.8561, Overall Accuracy: 0.5890\n",
      "Label 0 Accuracy: 0.7349\n",
      "Label 1 Accuracy: 0.5682\n",
      "Label 2 Accuracy: 0.4185\n",
      "Epoch 62/120, Loss: 0.8560, Overall Accuracy: 0.5876\n",
      "Label 0 Accuracy: 0.7329\n",
      "Label 1 Accuracy: 0.5660\n",
      "Label 2 Accuracy: 0.4188\n",
      "Epoch 63/120, Loss: 0.8558, Overall Accuracy: 0.5888\n",
      "Label 0 Accuracy: 0.7338\n",
      "Label 1 Accuracy: 0.5670\n",
      "Label 2 Accuracy: 0.4208\n",
      "Epoch 64/120, Loss: 0.8564, Overall Accuracy: 0.5892\n",
      "Label 0 Accuracy: 0.7363\n",
      "Label 1 Accuracy: 0.5667\n",
      "Label 2 Accuracy: 0.4189\n",
      "Epoch 65/120, Loss: 0.8561, Overall Accuracy: 0.5882\n",
      "Label 0 Accuracy: 0.7352\n",
      "Label 1 Accuracy: 0.5676\n",
      "Label 2 Accuracy: 0.4160\n",
      "Epoch 66/120, Loss: 0.8554, Overall Accuracy: 0.5887\n",
      "Label 0 Accuracy: 0.7345\n",
      "Label 1 Accuracy: 0.5682\n",
      "Label 2 Accuracy: 0.4179\n",
      "Epoch 67/120, Loss: 0.8559, Overall Accuracy: 0.5884\n",
      "Label 0 Accuracy: 0.7330\n",
      "Label 1 Accuracy: 0.5688\n",
      "Label 2 Accuracy: 0.4185\n",
      "Epoch 68/120, Loss: 0.8558, Overall Accuracy: 0.5889\n",
      "Label 0 Accuracy: 0.7365\n",
      "Label 1 Accuracy: 0.5666\n",
      "Label 2 Accuracy: 0.4179\n",
      "Epoch 69/120, Loss: 0.8553, Overall Accuracy: 0.5890\n",
      "Label 0 Accuracy: 0.7327\n",
      "Label 1 Accuracy: 0.5687\n",
      "Label 2 Accuracy: 0.4210\n",
      "Epoch 70/120, Loss: 0.8549, Overall Accuracy: 0.5902\n",
      "Label 0 Accuracy: 0.7337\n",
      "Label 1 Accuracy: 0.5706\n",
      "Label 2 Accuracy: 0.4216\n",
      "Epoch 71/120, Loss: 0.8553, Overall Accuracy: 0.5882\n",
      "Label 0 Accuracy: 0.7341\n",
      "Label 1 Accuracy: 0.5659\n",
      "Label 2 Accuracy: 0.4194\n",
      "Epoch 72/120, Loss: 0.8551, Overall Accuracy: 0.5899\n",
      "Label 0 Accuracy: 0.7349\n",
      "Label 1 Accuracy: 0.5693\n",
      "Label 2 Accuracy: 0.4203\n",
      "Epoch 73/120, Loss: 0.8551, Overall Accuracy: 0.5890\n",
      "Label 0 Accuracy: 0.7357\n",
      "Label 1 Accuracy: 0.5680\n",
      "Label 2 Accuracy: 0.4179\n",
      "Epoch 74/120, Loss: 0.8550, Overall Accuracy: 0.5901\n",
      "Label 0 Accuracy: 0.7350\n",
      "Label 1 Accuracy: 0.5694\n",
      "Label 2 Accuracy: 0.4208\n",
      "Epoch 75/120, Loss: 0.8549, Overall Accuracy: 0.5900\n",
      "Label 0 Accuracy: 0.7345\n",
      "Label 1 Accuracy: 0.5686\n",
      "Label 2 Accuracy: 0.4219\n",
      "Epoch 76/120, Loss: 0.8547, Overall Accuracy: 0.5907\n",
      "Label 0 Accuracy: 0.7354\n",
      "Label 1 Accuracy: 0.5707\n",
      "Label 2 Accuracy: 0.4211\n",
      "Epoch 77/120, Loss: 0.8548, Overall Accuracy: 0.5885\n",
      "Label 0 Accuracy: 0.7350\n",
      "Label 1 Accuracy: 0.5657\n",
      "Label 2 Accuracy: 0.4194\n",
      "Epoch 78/120, Loss: 0.8547, Overall Accuracy: 0.5886\n",
      "Label 0 Accuracy: 0.7321\n",
      "Label 1 Accuracy: 0.5688\n",
      "Label 2 Accuracy: 0.4203\n",
      "Epoch 79/120, Loss: 0.8549, Overall Accuracy: 0.5894\n",
      "Label 0 Accuracy: 0.7345\n",
      "Label 1 Accuracy: 0.5666\n",
      "Label 2 Accuracy: 0.4223\n",
      "Epoch 80/120, Loss: 0.8548, Overall Accuracy: 0.5886\n",
      "Label 0 Accuracy: 0.7349\n",
      "Label 1 Accuracy: 0.5680\n",
      "Label 2 Accuracy: 0.4176\n",
      "Epoch 81/120, Loss: 0.8471, Overall Accuracy: 0.5934\n",
      "Label 0 Accuracy: 0.7402\n",
      "Label 1 Accuracy: 0.5715\n",
      "Label 2 Accuracy: 0.4232\n",
      "Epoch 82/120, Loss: 0.8464, Overall Accuracy: 0.5947\n",
      "Label 0 Accuracy: 0.7398\n",
      "Label 1 Accuracy: 0.5745\n",
      "Label 2 Accuracy: 0.4246\n",
      "Epoch 83/120, Loss: 0.8461, Overall Accuracy: 0.5940\n",
      "Label 0 Accuracy: 0.7400\n",
      "Label 1 Accuracy: 0.5722\n",
      "Label 2 Accuracy: 0.4245\n",
      "Epoch 84/120, Loss: 0.8461, Overall Accuracy: 0.5941\n",
      "Label 0 Accuracy: 0.7409\n",
      "Label 1 Accuracy: 0.5732\n",
      "Label 2 Accuracy: 0.4227\n",
      "Epoch 85/120, Loss: 0.8459, Overall Accuracy: 0.5941\n",
      "Label 0 Accuracy: 0.7401\n",
      "Label 1 Accuracy: 0.5729\n",
      "Label 2 Accuracy: 0.4241\n",
      "Epoch 86/120, Loss: 0.8458, Overall Accuracy: 0.5939\n",
      "Label 0 Accuracy: 0.7400\n",
      "Label 1 Accuracy: 0.5725\n",
      "Label 2 Accuracy: 0.4239\n",
      "Epoch 87/120, Loss: 0.8456, Overall Accuracy: 0.5944\n",
      "Label 0 Accuracy: 0.7389\n",
      "Label 1 Accuracy: 0.5740\n",
      "Label 2 Accuracy: 0.4252\n",
      "Epoch 88/120, Loss: 0.8454, Overall Accuracy: 0.5942\n",
      "Label 0 Accuracy: 0.7387\n",
      "Label 1 Accuracy: 0.5722\n",
      "Label 2 Accuracy: 0.4268\n",
      "Epoch 89/120, Loss: 0.8455, Overall Accuracy: 0.5956\n",
      "Label 0 Accuracy: 0.7382\n",
      "Label 1 Accuracy: 0.5764\n",
      "Label 2 Accuracy: 0.4276\n",
      "Epoch 90/120, Loss: 0.8457, Overall Accuracy: 0.5944\n",
      "Label 0 Accuracy: 0.7385\n",
      "Label 1 Accuracy: 0.5720\n",
      "Label 2 Accuracy: 0.4282\n",
      "Epoch 91/120, Loss: 0.8452, Overall Accuracy: 0.5942\n",
      "Label 0 Accuracy: 0.7383\n",
      "Label 1 Accuracy: 0.5725\n",
      "Label 2 Accuracy: 0.4271\n",
      "Epoch 92/120, Loss: 0.8456, Overall Accuracy: 0.5937\n",
      "Label 0 Accuracy: 0.7381\n",
      "Label 1 Accuracy: 0.5711\n",
      "Label 2 Accuracy: 0.4272\n",
      "Epoch 93/120, Loss: 0.8455, Overall Accuracy: 0.5956\n",
      "Label 0 Accuracy: 0.7408\n",
      "Label 1 Accuracy: 0.5736\n",
      "Label 2 Accuracy: 0.4274\n",
      "Epoch 94/120, Loss: 0.8453, Overall Accuracy: 0.5937\n",
      "Label 0 Accuracy: 0.7361\n",
      "Label 1 Accuracy: 0.5731\n",
      "Label 2 Accuracy: 0.4275\n",
      "Epoch 95/120, Loss: 0.8453, Overall Accuracy: 0.5952\n",
      "Label 0 Accuracy: 0.7401\n",
      "Label 1 Accuracy: 0.5739\n",
      "Label 2 Accuracy: 0.4266\n",
      "Epoch 96/120, Loss: 0.8452, Overall Accuracy: 0.5958\n",
      "Label 0 Accuracy: 0.7375\n",
      "Label 1 Accuracy: 0.5770\n",
      "Label 2 Accuracy: 0.4285\n",
      "Epoch 97/120, Loss: 0.8452, Overall Accuracy: 0.5960\n",
      "Label 0 Accuracy: 0.7391\n",
      "Label 1 Accuracy: 0.5753\n",
      "Label 2 Accuracy: 0.4291\n",
      "Epoch 98/120, Loss: 0.8451, Overall Accuracy: 0.5945\n",
      "Label 0 Accuracy: 0.7383\n",
      "Label 1 Accuracy: 0.5725\n",
      "Label 2 Accuracy: 0.4280\n",
      "Epoch 99/120, Loss: 0.8451, Overall Accuracy: 0.5950\n",
      "Label 0 Accuracy: 0.7404\n",
      "Label 1 Accuracy: 0.5722\n",
      "Label 2 Accuracy: 0.4275\n",
      "Epoch 100/120, Loss: 0.8450, Overall Accuracy: 0.5951\n",
      "Label 0 Accuracy: 0.7371\n",
      "Label 1 Accuracy: 0.5744\n",
      "Label 2 Accuracy: 0.4296\n",
      "Epoch 101/120, Loss: 0.8452, Overall Accuracy: 0.5946\n",
      "Label 0 Accuracy: 0.7400\n",
      "Label 1 Accuracy: 0.5731\n",
      "Label 2 Accuracy: 0.4256\n",
      "Epoch 102/120, Loss: 0.8452, Overall Accuracy: 0.5940\n",
      "Label 0 Accuracy: 0.7383\n",
      "Label 1 Accuracy: 0.5720\n",
      "Label 2 Accuracy: 0.4273\n",
      "Epoch 103/120, Loss: 0.8448, Overall Accuracy: 0.5943\n",
      "Label 0 Accuracy: 0.7390\n",
      "Label 1 Accuracy: 0.5713\n",
      "Label 2 Accuracy: 0.4281\n",
      "Epoch 104/120, Loss: 0.8450, Overall Accuracy: 0.5939\n",
      "Label 0 Accuracy: 0.7388\n",
      "Label 1 Accuracy: 0.5734\n",
      "Label 2 Accuracy: 0.4245\n",
      "Epoch 105/120, Loss: 0.8449, Overall Accuracy: 0.5949\n",
      "Label 0 Accuracy: 0.7387\n",
      "Label 1 Accuracy: 0.5739\n",
      "Label 2 Accuracy: 0.4274\n",
      "Epoch 106/120, Loss: 0.8450, Overall Accuracy: 0.5936\n",
      "Label 0 Accuracy: 0.7387\n",
      "Label 1 Accuracy: 0.5702\n",
      "Label 2 Accuracy: 0.4272\n",
      "Epoch 107/120, Loss: 0.8448, Overall Accuracy: 0.5945\n",
      "Label 0 Accuracy: 0.7374\n",
      "Label 1 Accuracy: 0.5738\n",
      "Label 2 Accuracy: 0.4279\n",
      "Epoch 108/120, Loss: 0.8449, Overall Accuracy: 0.5946\n",
      "Label 0 Accuracy: 0.7376\n",
      "Label 1 Accuracy: 0.5730\n",
      "Label 2 Accuracy: 0.4291\n",
      "Epoch 109/120, Loss: 0.8448, Overall Accuracy: 0.5952\n",
      "Label 0 Accuracy: 0.7368\n",
      "Label 1 Accuracy: 0.5743\n",
      "Label 2 Accuracy: 0.4305\n",
      "Epoch 110/120, Loss: 0.8448, Overall Accuracy: 0.5939\n",
      "Label 0 Accuracy: 0.7384\n",
      "Label 1 Accuracy: 0.5727\n",
      "Label 2 Accuracy: 0.4258\n",
      "Epoch 111/120, Loss: 0.8448, Overall Accuracy: 0.5944\n",
      "Label 0 Accuracy: 0.7391\n",
      "Label 1 Accuracy: 0.5707\n",
      "Label 2 Accuracy: 0.4288\n",
      "Epoch 112/120, Loss: 0.8449, Overall Accuracy: 0.5950\n",
      "Label 0 Accuracy: 0.7379\n",
      "Label 1 Accuracy: 0.5740\n",
      "Label 2 Accuracy: 0.4288\n",
      "Epoch 113/120, Loss: 0.8449, Overall Accuracy: 0.5943\n",
      "Label 0 Accuracy: 0.7386\n",
      "Label 1 Accuracy: 0.5724\n",
      "Label 2 Accuracy: 0.4273\n",
      "Epoch 114/120, Loss: 0.8446, Overall Accuracy: 0.5939\n",
      "Label 0 Accuracy: 0.7400\n",
      "Label 1 Accuracy: 0.5711\n",
      "Label 2 Accuracy: 0.4257\n",
      "Epoch 115/120, Loss: 0.8447, Overall Accuracy: 0.5947\n",
      "Label 0 Accuracy: 0.7385\n",
      "Label 1 Accuracy: 0.5738\n",
      "Label 2 Accuracy: 0.4269\n",
      "Epoch 116/120, Loss: 0.8446, Overall Accuracy: 0.5941\n",
      "Label 0 Accuracy: 0.7378\n",
      "Label 1 Accuracy: 0.5730\n",
      "Label 2 Accuracy: 0.4269\n",
      "Epoch 117/120, Loss: 0.8445, Overall Accuracy: 0.5941\n",
      "Label 0 Accuracy: 0.7394\n",
      "Label 1 Accuracy: 0.5721\n",
      "Label 2 Accuracy: 0.4257\n",
      "Epoch 118/120, Loss: 0.8446, Overall Accuracy: 0.5945\n",
      "Label 0 Accuracy: 0.7383\n",
      "Label 1 Accuracy: 0.5742\n",
      "Label 2 Accuracy: 0.4263\n",
      "Epoch 119/120, Loss: 0.8447, Overall Accuracy: 0.5951\n",
      "Label 0 Accuracy: 0.7370\n",
      "Label 1 Accuracy: 0.5730\n",
      "Label 2 Accuracy: 0.4315\n",
      "Epoch 120/120, Loss: 0.8446, Overall Accuracy: 0.5950\n",
      "Label 0 Accuracy: 0.7373\n",
      "Label 1 Accuracy: 0.5739\n",
      "Label 2 Accuracy: 0.4298\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [02:16, 220.14it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [02:14, 223.11it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5182\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for seq, agent in models.items():\n",
    "    env = make_env(sequence_length=seq)\n",
    "    results[seq] = {}\n",
    "\n",
    "    language_importances, data, average_length = test_perturbation(env, agent, number_samples=300000)\n",
    "    language_importances_larger = np.where(language_importances > 0.02)\n",
    "    larger_inputs, larger_labels = generate_training_data_obs(language_importances_larger, data, sequence_length=seq, vocab_size=4)\n",
    "    dataset = PositionDataset(larger_inputs, larger_labels, \"cpu\")\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    input_size = larger_inputs.shape[1]\n",
    "    accuracy, model = train(120, dataloader, input_size, 0.001, \"cpu\")\n",
    "\n",
    "    language_importances_test, data_test, average_length_test = test_perturbation(env, agent, number_samples=30000)\n",
    "    language_importances_larger_test = np.where(language_importances_test > 0.02)\n",
    "    larger_inputs_test, larger_labels_test = generate_training_data_obs(language_importances_larger_test, data_test, sequence_length=seq, vocab_size=4)\n",
    "    dataset_test = PositionDataset(larger_inputs_test, larger_labels_test, \"cpu\")\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "    input_size = larger_inputs_test.shape[1]\n",
    "    accuracy_test = test(model, dataloader_test, \"cpu\")\n",
    "\n",
    "    language_importances_test_noise, data_test_noise, average_length_test_noise = test_perturbation(env, agent, number_samples=30000)\n",
    "    language_importances_larger_test_noise = np.where(language_importances_test_noise > 0.02)\n",
    "    larger_inputs_test_noise, larger_labels_test_noise = generate_training_data_obs(language_importances_larger_test_noise, data_test_noise, sequence_length=seq, vocab_size=4, noise=True)\n",
    "    dataset_test_noise = PositionDataset(larger_inputs_test_noise, larger_labels_test_noise, \"cpu\")\n",
    "    dataloader_test_noise = DataLoader(dataset_test_noise, batch_size=32, shuffle=True)\n",
    "    input_size = larger_inputs_test_noise.shape[1]\n",
    "    accuracy_test_noise = test(model, dataloader_test_noise, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: {'above threshold': 0.7620285219245635, 'below threshold': 0.7815622161671208, 'all': 0.6368836291913215}, 1: {'above threshold': 0.6119611263393969, 'below threshold': 0.7461061798693687, 'all': 0.5867644799508372}, 2: {'above threshold': 0.712832077443485, 'below threshold': 0.7211507028440667, 'all': 0.6332010400985356}, 3: {'above threshold': 0.8062483929030599, 'below threshold': 0.8038863791076181, 'all': 0.6753586630931736}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "\\textbf{Seq} & \\textbf{All} & \\textbf{\\textless T=0.02} & \\textbf{\\textgreater T=0.02} \\\\\n",
      "\\hline\n",
      "4 & 0.637 & 0.782 & 0.762 \\\\\n",
      "\\hline\n",
      "1 & 0.587 & 0.746 & 0.612 \\\\\n",
      "\\hline\n",
      "2 & 0.633 & 0.721 & 0.713 \\\\\n",
      "\\hline\n",
      "3 & 0.675 & 0.804 & 0.806 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Collectors Diagnostic classifier results}\n",
      "\\label{table:collectors_classifier}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table(data):\n",
    "    latex_table = \"\\\\begin{table}[h!]\\n\\\\centering\\n\\\\begin{tabular}{|c|c|c|c|}\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "    latex_table += \"\\\\textbf{Seq} & \\\\textbf{All} & \\\\textbf{\\\\textless T=0.02} & \\\\textbf{\\\\textgreater T=0.02} \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    for seq_len, values in data.items():\n",
    "        above_threshold_len = values['below threshold']\n",
    "        noised_share_len = values['above threshold']\n",
    "        all_utterances = values['all']\n",
    "        latex_table += f\"{seq_len} & {all_utterances:.3f} & {above_threshold_len:.3f} & {noised_share_len:.3f} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    latex_table += \"\\\\end{tabular}\\n\\\\caption{Collectors Diagnostic classifier results}\\n\\\\label{table:collectors_classifier}\\n\\\\end{table}\\n\"\n",
    "    return latex_table\n",
    "\n",
    "# Generate and print the LaTeX table\n",
    "latex_table = generate_latex_table(results)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

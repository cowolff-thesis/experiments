{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ThesisPackage.Environments.pong.multi_pong_language_continuous import PongEnv\n",
    "from ThesisPackage.RL.Decentralized_PPO.multi_ppo import PPO_Multi_Agent\n",
    "from ThesisPackage.RL.Decentralized_PPO.util import flatten_list, reverse_flatten_list_with_agent_list\n",
    "from ThesisPackage.Wrappers.vecWrapper import PettingZooVectorizationParallelWrapper\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    sequence_length = 2\n",
    "    vocab_size = 3\n",
    "    max_episode_steps = 512\n",
    "    env = PongEnv(width=20, height=20, vocab_size=vocab_size, sequence_length=sequence_length, max_episode_steps=max_episode_steps)\n",
    "    # env = ParallelFrameStack(env, 4)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    models = {}\n",
    "    path = \"/home/cowolff/Documents/GitHub/ma.pong_rl/models/checkpoints/\"\n",
    "    model_paths = os.listdir(path)\n",
    "    env = make_env()\n",
    "    for model in model_paths:\n",
    "        timestep = model.split(\"_\")[-1].split(\".\")[0]\n",
    "        agent = PPO_Multi_Agent(env, device=\"cpu\")\n",
    "        state_dict = torch.load(path + model)\n",
    "        agent.agent.load_state_dict(state_dict)\n",
    "        models[timestep] = agent\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cowolff/miniconda3/envs/Thesis/lib/python3.10/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float16\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "agents = load()\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(inputs, model, target_label_idx, baseline=None, steps=100):\n",
    "    if baseline is None:\n",
    "        baseline = torch.zeros_like(inputs)\n",
    "    assert baseline.shape == inputs.shape\n",
    "    \n",
    "    grads = []\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        scaled_input = torch.tensor(baseline + (float(i) / steps) * (inputs - baseline), requires_grad=True)\n",
    "        # scaled_input.requires_grad = True\n",
    "        logits = model(scaled_input)\n",
    "        loss = logits[0, target_label_idx]\n",
    "        loss.backward()\n",
    "        grads.append(scaled_input.grad.data.cpu().numpy())\n",
    "\n",
    "    avg_grads = np.average(grads[:-1], axis=0)\n",
    "    integrated_grad = (inputs.detach().cpu().numpy() - baseline.cpu().numpy()) * avg_grads\n",
    "\n",
    "    return integrated_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.00000000e+00 -1.58129956e+00 -1.85712326e+00 -3.78558340e-01\n",
      "  1.88339501e-02 -8.97281367e-05 -1.44373852e+00 -6.61838009e-01\n",
      "  1.59951383e-02 -1.60171943e-03  9.81933770e-01  1.00353330e+00] {1: {0: 27320, 1: 22634, 2: 27597}, 2: {0: 26495, 1: 25959, 2: 25097}}\n"
     ]
    }
   ],
   "source": [
    "def get_means(env, model, epochs):\n",
    "    means = []\n",
    "    tokens = {channel: {0: 0, 1: 1, 2: 2} for channel in [1, 2]}\n",
    "    for i in range(epochs):\n",
    "        obs, info = env.reset()\n",
    "        while True:\n",
    "            obs = [obs]\n",
    "            obs = np.array(flatten_list(obs))\n",
    "            means.append(obs)\n",
    "            obs = torch.tensor(obs, dtype=torch.float32, requires_grad=True)\n",
    "            with torch.no_grad():\n",
    "                action, _, _, _ = model.agent.get_action_and_value(obs)\n",
    "                action = reverse_flatten_list_with_agent_list(action, model.agents)\n",
    "            obs, rewards, terminations, truncations, info = env.step(action[0])\n",
    "            for channel in [1, 2]:\n",
    "                for paddle in env.agents:\n",
    "                    cur_token = int(obs[paddle][-1 * channel])\n",
    "                    tokens[channel][cur_token] += 1\n",
    "            if any([truncations[agent] or terminations[agent] for agent in env.agents]):\n",
    "                break\n",
    "    means = np.stack(means)\n",
    "    return means, tokens\n",
    "\n",
    "first_key = list(agents.keys())[0]\n",
    "means, tokens = get_means(env, agents[first_key], 100)\n",
    "means = means.reshape(-1, means.shape[-1])\n",
    "means = np.mean(means, axis=0)\n",
    "print(means, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_integrated_gradients(agent, means, timesteps=4096, tracking_agent=\"paddle_1\"):\n",
    "    saliencies = []\n",
    "    full_saliences = []\n",
    "    obs, info = env.reset()\n",
    "    average_length = []\n",
    "    average_noise_share = []\n",
    "    tokens = []\n",
    "    for i in range(timesteps):\n",
    "        timestep = 0\n",
    "    \n",
    "        timestep += 1\n",
    "        traking_index = env.agents.index(tracking_agent)\n",
    "        tokens.append(obs[tracking_agent][-1 * env.sequence_length:])\n",
    "        obs = [obs]\n",
    "        obs = np.array(flatten_list(obs))\n",
    "\n",
    "        obs_track = torch.tensor(np.expand_dims(obs[traking_index], axis=0), dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        baselines = torch.tensor(np.expand_dims(means, axis=0), dtype=torch.float32)\n",
    "        baselines[0] = 9.0\n",
    "        integrated_grads = integrated_gradients(obs_track, agent.agent.actor, 0, baseline=baselines, steps=20)\n",
    "\n",
    "        integrated_grads = (integrated_grads - integrated_grads.min()) / (integrated_grads.max() - integrated_grads.min())\n",
    "        language_saliences = np.sum(integrated_grads[0, -1 * env.sequence_length:])\n",
    "\n",
    "        obs = torch.tensor(obs, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            actions, _, _, _ = agent.agent.get_action_and_value(obs)\n",
    "            actions = reverse_flatten_list_with_agent_list(actions, agent.agents)\n",
    "\n",
    "        actions = actions[0]\n",
    "        actions = {agent: action.cpu().numpy() for agent, action in actions.items()}\n",
    "\n",
    "        saliencies.append(language_saliences)\n",
    "        full_saliences.append(integrated_grads)\n",
    "\n",
    "        obs, _, truncations, terminations, infos = env.step(actions)\n",
    "\n",
    "        if any([truncations[agent] or terminations[agent] for agent in env.agents]):\n",
    "            average_length.append(timestep)\n",
    "            obs, info = env.reset()\n",
    "            break\n",
    "        \n",
    "    full_saliences = np.stack(full_saliences, axis=0)\n",
    "    return saliencies, average_length, full_saliences, np.mean(average_noise_share), np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_saliency(agent, timesteps=4096, tracking_agent=\"paddle_1\"):\n",
    "    saliencies = []\n",
    "    full_saliences = []\n",
    "    obs, info = env.reset()\n",
    "    average_length = []\n",
    "    average_noise_share = []\n",
    "    tokens = []\n",
    "    noises = []\n",
    "    for i in range(timesteps):\n",
    "        timestep = 0\n",
    "\n",
    "        timestep += 1\n",
    "        traking_index = env.agents.index(tracking_agent)\n",
    "        tokens.append(obs[tracking_agent][-1 * env.sequence_length:])\n",
    "        obs = [obs]\n",
    "        obs = np.array(flatten_list(obs))\n",
    "\n",
    "        obs_track = torch.tensor(np.expand_dims(obs[traking_index], axis=0), dtype=torch.float32, requires_grad=True)\n",
    "        logits = agent.agent.actor(obs_track)\n",
    "\n",
    "        grad_tensor = torch.zeros_like(logits)\n",
    "        grad_tensor[:, :-6] = 1\n",
    "\n",
    "        logits.backward(grad_tensor)\n",
    "\n",
    "        saliency = obs_track.grad.data.abs()\n",
    "\n",
    "        saliency = saliency.numpy()\n",
    "        saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "\n",
    "        average_language = np.sum(saliency[:, -1 * env.sequence_length:])\n",
    "\n",
    "        obs = torch.tensor(obs, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            actions, _, _, _ = agent.agent.get_action_and_value(obs)\n",
    "            actions = reverse_flatten_list_with_agent_list(actions, agent.agents)\n",
    "\n",
    "        actions = actions[0]\n",
    "        actions = {agent: action.cpu().numpy() for agent, action in actions.items()}\n",
    "\n",
    "        saliencies.append(average_language)\n",
    "        full_saliences.append(saliency)\n",
    "\n",
    "        obs, _, truncations, terminations, infos = env.step(actions)\n",
    "\n",
    "        if any([truncations[agent] or terminations[agent] for agent in env.agents]):\n",
    "            average_length.append(timestep)\n",
    "            noises = []\n",
    "            average_noise_share.append(np.mean(noises))\n",
    "            obs, info = env.reset()\n",
    "            break\n",
    "    full_saliences = np.stack(full_saliences, axis=0)\n",
    "    return saliencies, average_length, full_saliences, np.mean(average_noise_share), np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5347/93629171.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scaled_input = torch.tensor(baseline + (float(i) / steps) * (inputs - baseline), requires_grad=True)\n",
      "/home/cowolff/miniconda3/envs/Thesis/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/cowolff/miniconda3/envs/Thesis/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.00000000e+00 -1.58129956e+00 -1.85712326e+00 -3.78558340e-01\n",
      "  1.88339501e-02 -8.97281367e-05 -1.44373852e+00 -6.61838009e-01\n",
      "  1.59951383e-02 -1.60171943e-03  9.81933770e-01  1.00353330e+00]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "means_saliencies = {}\n",
    "for agent_name in list(agents.keys()):\n",
    "    saliencies, average_length, full_saliences, _, _ = test_integrated_gradients(agents[agent_name], copy.deepcopy(means), timesteps=32768)\n",
    "    means_saliencies[agent_name] = np.mean(saliencies)\n",
    "\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3048': 1.3496369, '1524': 1.27434, '2540': 1.2016377, '3683': 1.3716365, '3175': 1.3308553, '1778': 1.2708437, '1016': 1.0753932, '762': 1.240871, '3429': 1.310518, '2286': 1.268866, '1270': 1.41319, '2667': 1.3216597, '2032': 1.3135335, '3302': 1.305145, '635': 0.91906345, '2159': 1.2909157, '1397': 1.2998027, '381': 1.1033112, '508': 1.1053104, '127': 1.0444089, '2921': 1.3981344, '1905': 1.3251836, '254': 1.0210496, '1651': 1.2641459, '1143': 1.2825036, '3810': 1.3267655, '3556': 1.2999666, '2794': 1.3242552, '889': 1.1656408, '2413': 1.2779877}\n"
     ]
    }
   ],
   "source": [
    "print(means_saliencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliencies, average_length, full_saliences, _, tokens = test(epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
